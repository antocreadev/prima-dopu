// ============================================================================
// AGENT INPAINTING - √âDITION D'IMAGE AVEC IMAGEN 3 (VERTEX AI)
// ============================================================================
// Utilise l'API Vertex AI Imagen 3 pour l'inpainting (insertion d'objets)
// Documentation: https://cloud.google.com/vertex-ai/generative-ai/docs/image/edit-insert-objects
// ============================================================================

import { GoogleAuth } from "google-auth-library";
import { saveBuffer } from "../../storage";
import type { PreparedImage, ReferenceAnalysis, ModificationTask, ImageAnalysis } from "../types";

// Configuration Vertex AI
const VERTEX_AI_REGION = import.meta.env.VERTEX_AI_REGION || process.env.VERTEX_AI_REGION || "europe-west1";
const GOOGLE_PROJECT_ID = import.meta.env.AI_GOOGLE_NAME || process.env.AI_GOOGLE_NAME || "";

// Debug: afficher le project ID au chargement
console.log(`[Inpainting] Project ID configur√©: ${GOOGLE_PROJECT_ID}`);

// Mod√®le Imagen 3 pour l'√©dition
const IMAGEN_MODEL = "imagen-3.0-capability-001";

// Client d'authentification Google (singleton)
let authClient: GoogleAuth | null = null;

/**
 * Obtient un token d'acc√®s OAuth pour Vertex AI via Application Default Credentials
 */
async function getAccessToken(): Promise<string> {
  if (!authClient) {
    authClient = new GoogleAuth({
      scopes: ["https://www.googleapis.com/auth/cloud-platform"],
    });
  }
  
  const client = await authClient.getClient();
  const tokenResponse = await client.getAccessToken();
  
  if (!tokenResponse.token) {
    throw new Error(
      "Impossible d'obtenir un token OAuth pour Vertex AI. " +
      "Assurez-vous d'avoir configur√© GOOGLE_APPLICATION_CREDENTIALS ou d'√™tre authentifi√© via gcloud."
    );
  }
  
  return tokenResponse.token;
}

/**
 * Configuration pour l'inpainting
 */
export interface InpaintingConfig {
  /** Dilatation du masque (0-1, recommand√© 0.01-0.03) */
  maskDilation?: number;
  /** Nombre d'√©tapes de sampling (35-75, recommand√© 35-50) */
  editSteps?: number;
  /** Nombre d'images √† g√©n√©rer (1-4) */
  sampleCount?: number;
  /** Mode d'√©dition */
  editMode?: "EDIT_MODE_INPAINT_INSERTION" | "EDIT_MODE_INPAINT_REMOVAL";
}

/**
 * Contexte complet pour construire un prompt d'inpainting riche
 */
export interface InpaintingContext {
  /** Instruction utilisateur originale */
  userInstruction: string;
  /** Analyse de l'image de r√©f√©rence */
  referenceAnalysis?: ReferenceAnalysis;
  /** T√¢che de modification du plan */
  task?: ModificationTask;
  /** Analyse de l'image originale */
  imageAnalysis?: ImageAnalysis;
}

/**
 * R√©sultat de l'inpainting
 */
export interface InpaintingResult {
  imagePath: string;
  mimeType: string;
  allResults?: Array<{
    imagePath: string;
    mimeType: string;
  }>;
}

/**
 * Appelle l'API Vertex AI Imagen 3 pour l'inpainting
 * @param baseImage - Image de base √† modifier
 * @param maskImage - Masque (blanc = zone √† modifier)
 * @param prompt - Prompt de g√©n√©ration (doit contenir la description d√©taill√©e de la r√©f√©rence)
 * @param config - Configuration
 */
async function callVertexAIImagen(
  baseImage: PreparedImage,
  maskImage: PreparedImage,
  prompt: string,
  config: InpaintingConfig = {}
): Promise<Array<{ bytesBase64Encoded: string; mimeType: string }>> {
  const {
    maskDilation = 0.02,
    editSteps = 50,
    sampleCount = 1,
    editMode = "EDIT_MODE_INPAINT_INSERTION",
  } = config;

  console.log(`   üé® Appel Vertex AI Imagen 3 (${IMAGEN_MODEL})`);
  console.log(`   üìç R√©gion: ${VERTEX_AI_REGION}`);
  console.log(`   üìù Prompt (${prompt.length} chars): ${prompt.substring(0, 150)}...`);
  console.log(`   ‚öôÔ∏è Config: dilation=${maskDilation}, steps=${editSteps}, samples=${sampleCount}`);

  // Construction des images de r√©f√©rence (RAW + MASK uniquement, pas de STYLE)
  // Note: REFERENCE_TYPE_STYLE n'est pas support√© pour l'inpainting
  const referenceImages: any[] = [
    // Image de base (√† modifier)
    {
      referenceType: "REFERENCE_TYPE_RAW",
      referenceId: 1,
      referenceImage: {
        bytesBase64Encoded: baseImage.base64,
      },
    },
    // Masque
    {
      referenceType: "REFERENCE_TYPE_MASK",
      referenceId: 2,
      referenceImage: {
        bytesBase64Encoded: maskImage.base64,
      },
      maskImageConfig: {
        maskMode: "MASK_MODE_USER_PROVIDED",
        dilation: maskDilation,
      },
    },
  ];

  // Construction du corps de la requ√™te selon la doc Vertex AI
  const requestBody = {
    instances: [
      {
        prompt: prompt,
        referenceImages: referenceImages,
      },
    ],
    parameters: {
      editConfig: {
        baseSteps: editSteps,
      },
      editMode: editMode,
      sampleCount: sampleCount,
    },
  };

  // URL de l'API Vertex AI
  const apiUrl = `https://${VERTEX_AI_REGION}-aiplatform.googleapis.com/v1/projects/${GOOGLE_PROJECT_ID}/locations/${VERTEX_AI_REGION}/publishers/google/models/${IMAGEN_MODEL}:predict`;

  console.log(`   üåê URL: ${apiUrl}`);
  
  // Obtenir le token OAuth2 via Application Default Credentials
  const accessToken = await getAccessToken();
  console.log(`   üîê Authentification: OAuth2 Token`);
  
  try {
    const response = await fetch(apiUrl, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${accessToken}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify(requestBody),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error(`   ‚ùå Erreur API Vertex AI: ${response.status}`);
      console.error(`   üìÑ D√©tails: ${errorText.substring(0, 500)}`);
      throw new Error(`Erreur Vertex AI (${response.status}): ${errorText}`);
    }

    const result = await response.json();

    if (!result.predictions || result.predictions.length === 0) {
      throw new Error("Aucune image g√©n√©r√©e par Vertex AI Imagen");
    }

    console.log(`   ‚úÖ ${result.predictions.length} image(s) g√©n√©r√©e(s)`);

    return result.predictions.map((pred: any) => ({
      bytesBase64Encoded: pred.bytesBase64Encoded,
      mimeType: pred.mimeType || "image/png",
    }));
  } catch (error: any) {
    console.error(`   ‚ùå Erreur lors de l'appel Vertex AI:`, error.message);
    throw error;
  }
}

/**
 * Agent Inpainting - G√©n√®re une image avec inpainting via Imagen 3
 * 
 * @param originalImage - Image originale √† modifier
 * @param maskImage - Masque noir/blanc (blanc = zone √† modifier)
 * @param prompt - Prompt complet de g√©n√©ration (construit par buildInpaintingPromptFromContext)
 * @param generationId - ID de g√©n√©ration pour le nommage du fichier
 * @param styleReferenceImage - Image de r√©f√©rence pour le style (optionnel mais recommand√©)
 * @param config - Configuration optionnelle
 */
export async function generateWithInpainting(
  originalImage: PreparedImage,
  maskImage: PreparedImage,
  prompt: string,
  generationId: string,
  config: InpaintingConfig = {}
): Promise<InpaintingResult> {
  console.log("\n" + "‚îÄ".repeat(60));
  console.log("üñåÔ∏è  AGENT INPAINTING - IMAGEN 3 (VERTEX AI)");
  console.log("‚îÄ".repeat(60));
  console.log(`   üìê Image originale: ${((originalImage.sizeBytes || originalImage.base64.length) / 1024).toFixed(0)} KB`);
  console.log(`   üé≠ Masque: ${((maskImage.sizeBytes || maskImage.base64.length) / 1024).toFixed(0)} KB`);

  // Appel √† l'API Vertex AI (la description de la r√©f√©rence est dans le prompt)
  const predictions = await callVertexAIImagen(
    originalImage,
    maskImage,
    prompt,
    config
  );

  // Sauvegarder la premi√®re image (principale)
  const mainPrediction = predictions[0];
  const extension = mainPrediction.mimeType.split("/")[1]?.replace("jpeg", "jpg") || "png";
  const fileName = `inpainted_${generationId}.${extension}`;
  const imageBuffer = Buffer.from(mainPrediction.bytesBase64Encoded, "base64");

  const imagePath = await saveBuffer(imageBuffer, fileName, "generated");

  console.log(`   üíæ Sauvegard√©: ${fileName} (${(imageBuffer.length / 1024).toFixed(0)} KB)`);

  // Sauvegarder les images suppl√©mentaires si demand√©es
  const allResults: Array<{ imagePath: string; mimeType: string }> = [
    { imagePath, mimeType: mainPrediction.mimeType },
  ];

  for (let i = 1; i < predictions.length; i++) {
    const pred = predictions[i];
    const ext = pred.mimeType.split("/")[1]?.replace("jpeg", "jpg") || "png";
    const altFileName = `inpainted_${generationId}_alt${i}.${ext}`;
    const altBuffer = Buffer.from(pred.bytesBase64Encoded, "base64");
    const altPath = await saveBuffer(altBuffer, altFileName, "generated");
    allResults.push({ imagePath: altPath, mimeType: pred.mimeType });
    console.log(`   üíæ Alternative ${i}: ${altFileName}`);
  }

  console.log("‚îÄ".repeat(60) + "\n");

  return {
    imagePath,
    mimeType: mainPrediction.mimeType,
    allResults: allResults.length > 1 ? allResults : undefined,
  };
}

/**
 * Construit un prompt complet et optimis√© pour l'inpainting
 * en utilisant TOUT le contexte d'analyse disponible
 */
export function buildInpaintingPromptFromContext(context: InpaintingContext): string {
  const { userInstruction, referenceAnalysis, task, imageAnalysis } = context;
  
  const lines: string[] = [];
  
  // === INSTRUCTION PRINCIPALE ===
  lines.push(`INSTRUCTION: ${userInstruction}`);
  
  // === DESCRIPTION DE L'√âL√âMENT √Ä INS√âRER ===
  if (referenceAnalysis) {
    lines.push("");
    lines.push("√âL√âMENT √Ä INS√âRER:");
    
    if (referenceAnalysis.description) {
      lines.push(`- Description: ${referenceAnalysis.description}`);
    }
    if (referenceAnalysis.category) {
      lines.push(`- Type: ${referenceAnalysis.category}`);
    }
    if (referenceAnalysis.material) {
      lines.push(`- Mat√©riau: ${referenceAnalysis.material}`);
    }
    if (referenceAnalysis.mainColor) {
      lines.push(`- Couleur principale: ${referenceAnalysis.mainColor}`);
    }
    if (referenceAnalysis.secondaryColors && referenceAnalysis.secondaryColors.length > 0) {
      lines.push(`- Couleurs secondaires: ${referenceAnalysis.secondaryColors.join(", ")}`);
    }
    if (referenceAnalysis.style) {
      lines.push(`- Style: ${referenceAnalysis.style}`);
    }
    if (referenceAnalysis.finish) {
      lines.push(`- Finition: ${referenceAnalysis.finish}`);
    }
    if (referenceAnalysis.pattern) {
      lines.push(`- Motif/Pattern: ${referenceAnalysis.pattern}`);
    }
    if (referenceAnalysis.dimensions) {
      lines.push(`- Dimensions estim√©es: ${referenceAnalysis.dimensions}`);
    }
  }
  
  // === CONTEXTE DE LA T√ÇCHE ===
  if (task) {
    lines.push("");
    lines.push("D√âTAILS DE LA MODIFICATION:");
    
    if (task.actionType) {
      const actionLabels: Record<string, string> = {
        "add_element": "Ajouter un nouvel √©l√©ment",
        "replace_object": "Remplacer un objet existant",
        "apply_texture": "Appliquer une texture/mat√©riau",
      };
      lines.push(`- Action: ${actionLabels[task.actionType] || task.actionType}`);
    }
    
    if (task.quantity && task.quantity > 1) {
      lines.push(`- Quantit√©: ${task.quantity} √©l√©ment(s)`);
    }
    
    if (task.quantityText) {
      lines.push(`- Description quantit√©: ${task.quantityText}`);
    }
    
    if (task.specificInstructions) {
      lines.push(`- Instructions: ${task.specificInstructions}`);
    }
    
    if (task.positionConstraints) {
      if (task.positionConstraints.side) {
        lines.push(`- C√¥t√©: ${task.positionConstraints.side}`);
      }
      if (task.positionConstraints.description) {
        lines.push(`- Zone: ${task.positionConstraints.description}`);
      }
    }
    
    if (task.targetZone) {
      lines.push(`- Zone cible: ${task.targetZone}`);
    }
    
    // Surface cible
    if (task.targetSurface) {
      lines.push("");
      lines.push("SURFACE CIBLE:");
      lines.push(`- Nom: ${task.targetSurface.name}`);
      if (task.targetSurface.boundaries) {
        lines.push(`- Limites: ${task.targetSurface.boundaries}`);
      }
      if (task.targetSurface.currentMaterial) {
        lines.push(`- Mat√©riau actuel √† remplacer: ${task.targetSurface.currentMaterial}`);
      }
    }
    
    // Objet cible
    if (task.targetObject) {
      lines.push("");
      lines.push("OBJET CIBLE:");
      lines.push(`- Nom: ${task.targetObject.name}`);
      if (task.targetObject.position) {
        lines.push(`- Position: ${task.targetObject.position}`);
      }
      if (task.targetObject.style) {
        lines.push(`- Style actuel: ${task.targetObject.style}`);
      }
      if (task.targetObject.estimatedDimensions) {
        lines.push(`- Dimensions: ${task.targetObject.estimatedDimensions}`);
      }
    }
  }
  
  // === CONTEXTE DE L'IMAGE ORIGINALE ===
  if (imageAnalysis) {
    lines.push("");
    lines.push("CONTEXTE DE LA SC√àNE:");
    lines.push(`- Type d'espace: ${imageAnalysis.spaceType}`);
    lines.push(`- Environnement: ${imageAnalysis.environment === "interior" ? "Int√©rieur" : imageAnalysis.environment === "exterior" ? "Ext√©rieur" : "Mixte"}`);
    
    if (imageAnalysis.lighting) {
      lines.push(`- √âclairage: ${imageAnalysis.lighting.type || "naturel"}, direction ${imageAnalysis.lighting.direction || "diffuse"}`);
      if (imageAnalysis.lighting.temperature) {
        lines.push(`- Temp√©rature couleur: ${imageAnalysis.lighting.temperature}`);
      }
    }
    
    if (imageAnalysis.perspective) {
      if (imageAnalysis.perspective.viewType) {
        lines.push(`- Perspective: ${imageAnalysis.perspective.viewType}`);
      }
      if (imageAnalysis.perspective.cameraHeight) {
        lines.push(`- Hauteur cam√©ra: ${imageAnalysis.perspective.cameraHeight}`);
      }
      if (imageAnalysis.perspective.description) {
        lines.push(`- Description: ${imageAnalysis.perspective.description}`);
      }
    }
  }
  
  // === CONSEILS D'INT√âGRATION ===
  if (referenceAnalysis?.integrationTips && referenceAnalysis.integrationTips.length > 0) {
    lines.push("");
    lines.push("CONSEILS D'INT√âGRATION:");
    for (const tip of referenceAnalysis.integrationTips) {
      lines.push(`- ${tip}`);
    }
  }
  
  // === INSTRUCTIONS DE QUALIT√â ===
  lines.push("");
  lines.push("EXIGENCES DE QUALIT√â:");
  lines.push("- Rendu PHOTOR√âALISTE, indiscernable d'une vraie photo");
  lines.push("- Int√©gration NATURELLE avec l'√©clairage existant de la sc√®ne");
  lines.push("- Respecter la PERSPECTIVE exacte de l'image originale");
  lines.push("- G√©n√©rer des OMBRES coh√©rentes avec la source de lumi√®re");
  lines.push("- L'√©l√©ment doit sembler PHOTOGRAPHI√â dans la sc√®ne, pas ajout√© num√©riquement");
  lines.push("- Conserver le M√äME CADRAGE que l'image originale (pas de zoom/recadrage)");
  
  return lines.join("\n");
}

/**
 * G√©n√®re un prompt simplifi√© pour l'inpainting (fallback)
 * @deprecated Pr√©f√©rer buildInpaintingPromptFromContext
 */
export function buildInpaintingPrompt(
  userInstruction: string,
  referenceDescription?: string,
  referenceStyle?: string,
  referenceColor?: string
): string {
  let prompt = userInstruction;

  // Ajouter les d√©tails de la r√©f√©rence si disponibles
  if (referenceDescription) {
    prompt += `. L'√©l√©ment doit ressembler √†: ${referenceDescription}`;
  }

  if (referenceStyle) {
    prompt += `. Style: ${referenceStyle}`;
  }

  if (referenceColor) {
    prompt += `. Couleur dominante: ${referenceColor}`;
  }

  // Ajouter des instructions de qualit√©
  prompt += ". Rendu photor√©aliste, int√©gration naturelle avec l'√©clairage et la perspective de l'image originale.";

  return prompt;
}

/**
 * V√©rifie si une instruction poss√®de un masque valide pour l'inpainting
 */
export function canUseInpainting(instruction: { maskImagePath?: string }): boolean {
  return !!instruction.maskImagePath && instruction.maskImagePath.length > 0;
}
