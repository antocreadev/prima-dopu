import { GoogleGenAI } from "@google/genai";
import heicConvert from "heic-convert";
import sharp from "sharp";
import { getImageBuffer, saveBuffer } from "./storage";

// ============================================================================
// SYST√àME AGENTIQUE POLYVALENT POUR VISUALISATION AVANT/APR√àS
// ============================================================================
// Architecture Multi-Agent pour tous m√©tiers d'am√©nagement :
// - R√©novation int√©rieure/ext√©rieure
// - D√©coration et agencement
// - Ameublement et mobilier
// - Jardinage et paysagisme
// - √âlectricit√© et √©quipements
// ============================================================================
// 1. Agent Analyste (Gemini Flash) - Comprend l'image (surfaces ET objets)
// 2. Agent Planificateur (Gemini Flash) - Classifie et mappe les modifications
// 3. Agent G√©n√©rateur (Nano Banana) - G√©n√®re l'image avec pr√©cision
// ============================================================================

const ai = new GoogleGenAI({
  apiKey:
    import.meta.env.AI_GOOGLE_API_KEY || process.env.AI_GOOGLE_API_KEY || "",
});

// Mod√®les utilis√©s dans l'architecture agentique
const MODELS = {
  ANALYZER: "gemini-2.5-flash", // Agent analyste & planificateur (texte)
  GENERATOR: "gemini-3-pro-image-preview", // Nano Banana Pro - meilleure qualit√©, thinking, 4K
} as const;

// Configuration de g√©n√©ration d'image (Nano Banana Pro)
const IMAGE_CONFIG = {
  aspectRatio: "4:3" as const, // Aspect ratio pour photos de pi√®ces
  imageSize: "2K" as const, // R√©solution: "1K", "2K", ou "4K"
} as const;

// Configuration robuste avec retry
const CONFIG = {
  maxRetries: 3,
  initialDelayMs: 2000,
  maxDelayMs: 15000,
  backoffMultiplier: 2,
  maxImageSizeBytes: 4 * 1024 * 1024,
};

// ============================================================================
// TYPES & INTERFACES
// ============================================================================

// Type d'√©l√©ment dans l'image
export type ElementCategory =
  | "surface" // Murs, sols, plafonds, fa√ßades
  | "furniture" // Meubles (tables, chaises, canap√©s, lits, armoires)
  | "lighting" // Luminaires (lustres, lampes, spots, appliques)
  | "decoration" // D√©co (tableaux, miroirs, vases, rideaux, tapis)
  | "equipment" // √âquipements (prises, interrupteurs, radiateurs)
  | "outdoor" // Ext√©rieur (plantes, pergolas, cl√¥tures, terrasses)
  | "fixture" // √âl√©ments fixes (√©viers, baignoires, sanitaires)
  | "appliance"; // √âlectrom√©nager (cuisine, buanderie)

// Type de modification √† effectuer
export type ModificationAction =
  | "replace_material" // Changer le mat√©riau d'une surface (peinture, carrelage)
  | "replace_object" // Remplacer un objet entier par un autre
  | "add_element" // Ajouter un nouvel √©l√©ment
  | "remove_element" // Retirer un √©l√©ment
  | "modify_style"; // Modifier le style (couleur, finition)

export type ModificationType =
  | "floor"
  | "wall"
  | "ceiling"
  | "furniture"
  | "add_element"
  | "facade"
  | "outdoor"
  | "lighting"
  | "decoration"
  | "equipment"
  | "custom";

export interface GenerationInstruction {
  location: string;
  referenceImagePath: string;
  referenceName?: string;
  modificationType?: ModificationType;
  additionalDetails?: string;
}

export interface GenerationResult {
  imagePath: string;
  description: string;
  attempts: number;
  analysisDetails?: ImageAnalysis;
}

export interface GenerationOptions {
  aspectRatio?: "1:1" | "3:4" | "4:3" | "9:16" | "16:9";
}

// R√©sultat de l'analyse agentique de l'image
interface ImageAnalysis {
  roomType: string;
  visibleZones: ZoneInfo[];
  lighting: string;
  perspective: string;
  existingMaterials: MaterialInfo[];
  // Nouvelles propri√©t√©s pour une analyse plus compl√®te
  visibleObjects?: ObjectInfo[]; // Objets identifi√©s (meubles, d√©co, plantes)
}

interface ObjectInfo {
  id: string;
  name: string;
  category: string; // table, chaise, canap√©, lampe, plante, tableau, etc.
  description: string;
  position: string; // o√π dans l'image
  style: string; // moderne, classique, industriel, etc.
  material: string; // bois, m√©tal, tissu, etc.
  color: string;
}

interface ZoneInfo {
  id: string;
  name: string;
  description: string;
  boundaries: string;
  currentMaterial: string;
  // Nouvelles propri√©t√©s pour distinguer surfaces et objets
  elementType?: "surface" | "object"; // surface = mur/sol, object = meuble/d√©co
  objectCategory?: string; // table, chaise, lampe, plante, tableau, etc.
}

interface MaterialInfo {
  zone: string;
  type: string;
  color: string;
  texture: string;
}

// Plan de modification g√©n√©r√© par l'agent planificateur
interface ModificationPlan {
  originalAnalysis: ImageAnalysis;
  tasks: ModificationTask[];
  globalPrompt: string;
}

interface ModificationTask {
  priority: number;
  zone?: ZoneInfo; // Pour les surfaces
  targetObject?: ObjectInfo; // Pour les objets √† remplacer
  targetMaterial: string;
  referenceIndex: number;
  specificInstructions: string;
  // Nouvelles propri√©t√©s pour distinguer le type d'action
  actionType: "apply_texture" | "replace_object" | "add_element";
  referenceAnalysis?: ReferenceAnalysis;
}

// ============================================================================
// UTILITAIRES
// ============================================================================

// Formats Apple n√©cessitant une conversion
const APPLE_FORMATS = ["heic", "heif", "hif"];

function getMimeType(filePath: string): string {
  const ext = filePath.toLowerCase().split(".").pop();
  const mimeTypes: Record<string, string> = {
    jpg: "image/jpeg",
    jpeg: "image/jpeg",
    png: "image/png",
    gif: "image/gif",
    webp: "image/webp",
  };
  return mimeTypes[ext || ""] || "image/jpeg";
}

async function sleep(ms: number): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

/**
 * Pr√©pare une image pour l'API Gemini
 * - Lit l'image depuis S3
 * - Convertit les formats Apple (HEIC, HEIF) en JPEG via heic-convert
 * - Optimise les images trop volumineuses (>4MB) via sharp
 */
async function prepareImageForAPI(
  imagePath: string
): Promise<{ base64: string; mimeType: string }> {
  const ext = imagePath.toLowerCase().split(".").pop() || "";
  let buffer: Buffer;
  try {
    buffer = await getImageBuffer(imagePath);
  } catch (error: any) {
    console.error(`Erreur lecture image S3: ${imagePath}`, error);
    throw new Error(`Image introuvable sur S3: ${imagePath}. ${error?.message || ''}`);
  }
  let mimeType = getMimeType(imagePath);

  // Conversion des formats Apple (HEIC, HEIF) avec heic-convert
  if (APPLE_FORMATS.includes(ext)) {
    console.log(`   üîÑ Conversion ${ext.toUpperCase()} ‚Üí JPEG pour API...`);
    try {
      const converted = await heicConvert({
        buffer: buffer,
        format: "JPEG",
        quality: 0.9,
      });
      buffer = Buffer.from(converted);
      mimeType = "image/jpeg";
      console.log(
        `   ‚úì Converti pour API: ${(buffer.length / 1024).toFixed(0)} KB`
      );
    } catch (error) {
      console.error(`   ‚ùå Erreur conversion ${ext}:`, error);
      throw new Error(
        `Impossible de convertir ${ext.toUpperCase()}. Format non support√©.`
      );
    }
  }

  // Optimisation si l'image est trop volumineuse (>4MB) avec sharp
  if (buffer.length > CONFIG.maxImageSizeBytes) {
    console.log(
      `   üìê Image trop volumineuse (${(buffer.length / 1024 / 1024).toFixed(
        1
      )}MB), optimisation...`
    );
    try {
      // R√©duire la qualit√© et/ou les dimensions
      buffer = Buffer.from(
        await sharp(buffer)
          .resize(2048, 2048, { fit: "inside", withoutEnlargement: true })
          .jpeg({ quality: 85 })
          .toBuffer()
      );
      mimeType = "image/jpeg";
      console.log(`   ‚úì Optimis√©: ${(buffer.length / 1024).toFixed(0)} KB`);
    } catch (error) {
      console.warn(
        `   ‚ö†Ô∏è Optimisation √©chou√©e, utilisation de l'image originale`
      );
    }
  }

  return { base64: buffer.toString("base64"), mimeType };
}

// ============================================================================
// AGENT 1: ANALYSTE D'IMAGE (Gemini Flash - Texte)
// ============================================================================
// Analyse l'image en profondeur pour identifier toutes les zones modifiables

async function analyzeImageWithAgent(imageData: {
  base64: string;
  mimeType: string;
}): Promise<ImageAnalysis> {
  console.log("   üîç Agent Analyste: Analyse intelligente de l'image...");

  const analysisPrompt = `Tu es un expert en am√©nagement int√©rieur/ext√©rieur, d√©coration, et design d'espace.
Analyse cette image de mani√®re EXHAUSTIVE pour identifier:
1. TOUTES les SURFACES modifiables (murs, sols, plafonds, fa√ßades)
2. TOUS les OBJETS pr√©sents (meubles, luminaires, d√©corations, plantes, √©quipements)

R√©ponds UNIQUEMENT avec ce JSON valide (sans markdown, sans backticks):
{
  "roomType": "type d'espace (salon, chambre, cuisine, terrasse, jardin, bureau...)",
  "visibleZones": [
    {
      "id": "wall_left",
      "name": "Mur de gauche",
      "description": "Mur vertical situ√© sur le c√¥t√© gauche de l'image",
      "boundaries": "Du coin inf√©rieur gauche jusqu'au plafond",
      "currentMaterial": "Peinture blanche mate",
      "elementType": "surface"
    },
    {
      "id": "floor_main",
      "name": "Sol",
      "description": "Surface horizontale au sol",
      "boundaries": "Toute la surface visible du sol",
      "currentMaterial": "Parquet bois clair",
      "elementType": "surface"
    }
  ],
  "visibleObjects": [
    {
      "id": "table_dining",
      "name": "Table √† manger",
      "category": "table",
      "description": "Grande table rectangulaire avec plateau en bois",
      "position": "Centre de la pi√®ce",
      "style": "moderne",
      "material": "bois massif",
      "color": "ch√™ne naturel"
    },
    {
      "id": "chairs_dining",
      "name": "Chaises de salle √† manger",
      "category": "chaise",
      "description": "Ensemble de 4 chaises assorties",
      "position": "Autour de la table",
      "style": "scandinave",
      "material": "bois et tissu",
      "color": "blanc et gris"
    },
    {
      "id": "lamp_ceiling",
      "name": "Suspension luminaire",
      "category": "luminaire",
      "description": "Lustre moderne au-dessus de la table",
      "position": "Au plafond, centre",
      "style": "industriel",
      "material": "m√©tal",
      "color": "noir"
    },
    {
      "id": "plant_corner",
      "name": "Plante verte",
      "category": "plante",
      "description": "Grande plante d'int√©rieur en pot",
      "position": "Coin gauche",
      "style": "naturel",
      "material": "v√©g√©tal",
      "color": "vert"
    }
  ],
  "lighting": "Lumi√®re naturelle venant de la fen√™tre √† droite",
  "perspective": "Vue en l√©g√®re plong√©e depuis l'entr√©e",
  "existingMaterials": [
    {"zone": "Sol", "type": "parquet", "color": "ch√™ne clair", "texture": "bois vein√©"}
  ]
}

CAT√âGORIES D'OBJETS √Ä IDENTIFIER:
- Meubles: table, chaise, canap√©, fauteuil, lit, armoire, buffet, bureau, √©tag√®re, commode
- Luminaires: lustre, suspension, lampadaire, lampe de table, applique, spot
- D√©coration: tableau, miroir, vase, sculpture, coussin, rideau, tapis, horloge
- Plantes: plante d'int√©rieur, arbre, arbuste, fleurs, jardini√®re
- √âquipements: radiateur, climatiseur, t√©l√©vision, ordinateur
- Cuisine: plan de travail, cr√©dence, √©vier, robinet, √©lectrom√©nager
- Salle de bain: lavabo, baignoire, douche, toilettes, miroir

R√àGLES D'IDENTIFICATION:
- Identifie CHAQUE surface visible s√©par√©ment
- Identifie CHAQUE objet/meuble visible
- Sois PR√âCIS sur les mat√©riaux, couleurs, styles
- Utilise des IDs uniques et descriptifs`;

  try {
    const response = await ai.models.generateContent({
      model: MODELS.ANALYZER,
      contents: [
        { text: analysisPrompt },
        {
          inlineData: { mimeType: imageData.mimeType, data: imageData.base64 },
        },
      ],
    });

    const text = response.candidates?.[0]?.content?.parts?.[0]?.text || "";

    // Extraire le JSON
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      const analysis = JSON.parse(jsonMatch[0]) as ImageAnalysis;
      console.log(`   ‚úì Type: ${analysis.roomType}`);
      console.log(`   ‚úì ${analysis.visibleZones.length} surfaces identifi√©es:`);
      for (const zone of analysis.visibleZones) {
        console.log(
          `      - ${zone.name} (${zone.id}): ${zone.currentMaterial}`
        );
      }
      if (analysis.visibleObjects && analysis.visibleObjects.length > 0) {
        console.log(
          `   ‚úì ${analysis.visibleObjects.length} objets identifi√©s:`
        );
        for (const obj of analysis.visibleObjects) {
          console.log(
            `      - ${obj.name} (${obj.category}): ${obj.style} ${obj.material}`
          );
        }
      }
      return analysis;
    }
  } catch (error) {
    console.warn("   ‚ö†Ô∏è Parsing de l'analyse √©chou√©, utilisation du fallback");
  }

  // Fallback avec des zones g√©n√©riques
  return {
    roomType: "espace int√©rieur",
    visibleZones: [
      {
        id: "wall_left",
        name: "Mur gauche",
        description: "Mur c√¥t√© gauche",
        boundaries: "gauche de l'image",
        currentMaterial: "inconnu",
        elementType: "surface",
      },
      {
        id: "wall_right",
        name: "Mur droit",
        description: "Mur c√¥t√© droit",
        boundaries: "droite de l'image",
        currentMaterial: "inconnu",
        elementType: "surface",
      },
      {
        id: "wall_back",
        name: "Mur du fond",
        description: "Mur face",
        boundaries: "fond de l'image",
        currentMaterial: "inconnu",
        elementType: "surface",
      },
      {
        id: "floor_main",
        name: "Sol",
        description: "Surface au sol",
        boundaries: "partie basse",
        currentMaterial: "inconnu",
        elementType: "surface",
      },
    ],
    visibleObjects: [],
    lighting: "√©clairage standard",
    perspective: "vue frontale",
    existingMaterials: [],
  };
}

// ============================================================================
// AGENT 1B: ANALYSE DE LA R√âF√âRENCE (Mat√©riau vs Objet)
// ============================================================================
// D√©termine si l'image de r√©f√©rence est un mat√©riau/texture ou un objet complet

interface ReferenceAnalysis {
  type: "material" | "object";
  category: string; // "carrelage", "peinture", "table", "chaise", etc.
  description: string;
  mainColor: string;
  style: string; // moderne, classique, industriel, etc.
  material: string; // bois, m√©tal, tissu, etc.
  action: "apply_texture" | "replace_object" | "add_element";
}

async function analyzeReferenceImage(imageData: {
  base64: string;
  mimeType: string;
}): Promise<ReferenceAnalysis> {
  console.log("   üé® Analyse de l'image de r√©f√©rence...");

  const referencePrompt = `Tu es un expert en design d'int√©rieur et d√©coration.
Analyse cette image de R√âF√âRENCE et d√©termine ce qu'elle repr√©sente.

QUESTION PRINCIPALE: Est-ce un MAT√âRIAU/TEXTURE ou un OBJET COMPLET?

MAT√âRIAU/TEXTURE = √©chantillon de surface sans forme d√©finie
Exemples: carrelage, parquet, peinture, b√©ton cir√©, pierre, tissu, papier peint, brique

OBJET COMPLET = √©l√©ment avec une forme et structure propre
Exemples: table, chaise, canap√©, lampe, plante, tableau, lit, bureau, luminaire

R√©ponds UNIQUEMENT avec ce JSON (sans markdown, sans backticks):
{
  "type": "material" ou "object",
  "category": "cat√©gorie pr√©cise (ex: table √† manger, parquet chevron, lustre moderne)",
  "description": "description d√©taill√©e de ce que montre l'image",
  "mainColor": "couleur dominante",
  "style": "style d√©co (moderne, scandinave, industriel, classique, boh√®me, minimaliste)",
  "material": "mati√®re principale (bois, m√©tal, verre, tissu, c√©ramique, etc.)",
  "action": "apply_texture" si mat√©riau, "replace_object" si objet existant √† remplacer, "add_element" si ajout
}

INDICES pour identifier un MAT√âRIAU:
- Image en gros plan de texture
- Pas de forme reconnaissable d'objet
- Pattern r√©p√©titif
- √âchantillon sans contexte

INDICES pour identifier un OBJET:
- Forme compl√®te visible (meuble, luminaire, plante)
- Objet photographi√© en entier ou partiellement
- √âl√©ment avec structure 3D
- Produit identifiable

Sois PR√âCIS dans ta classification, c'est CRUCIAL pour la g√©n√©ration.`;

  try {
    const response = await ai.models.generateContent({
      model: MODELS.ANALYZER,
      contents: [
        { text: referencePrompt },
        {
          inlineData: { mimeType: imageData.mimeType, data: imageData.base64 },
        },
      ],
    });

    const text = response.candidates?.[0]?.content?.parts?.[0]?.text || "";
    const jsonMatch = text.match(/\{[\s\S]*\}/);

    if (jsonMatch) {
      const analysis = JSON.parse(jsonMatch[0]) as ReferenceAnalysis;
      console.log(`   ‚úì Type de r√©f√©rence: ${analysis.type.toUpperCase()}`);
      console.log(`   ‚úì Cat√©gorie: ${analysis.category}`);
      console.log(`   ‚úì Action: ${analysis.action}`);
      console.log(
        `   ‚úì Style: ${analysis.style}, Mati√®re: ${analysis.material}`
      );
      return analysis;
    }
  } catch (error) {
    console.warn("   ‚ö†Ô∏è Analyse de r√©f√©rence √©chou√©e, fallback mat√©riau");
  }

  // Fallback: on suppose que c'est un mat√©riau
  return {
    type: "material",
    category: "mat√©riau",
    description: "Image de r√©f√©rence non analys√©e",
    mainColor: "inconnu",
    style: "neutre",
    material: "inconnu",
    action: "apply_texture",
  };
}

// ============================================================================
// AGENT 2: PLANIFICATEUR INTELLIGENT (Gemini Flash - Texte)
// ============================================================================
// Interpr√®te les instructions utilisateur, analyse les r√©f√©rences, et cr√©e le plan

async function planModificationsWithAgent(
  analysis: ImageAnalysis,
  instructions: GenerationInstruction[],
  referenceImages: { base64: string; mimeType: string }[]
): Promise<ModificationPlan> {
  console.log(
    "   üìã Agent Planificateur: Analyse intelligente des modifications..."
  );

  // 1. Analyser chaque image de r√©f√©rence
  console.log("\n   üîç √âtape 1: Analyse des images de r√©f√©rence...");
  const referenceAnalyses: ReferenceAnalysis[] = [];
  for (let i = 0; i < referenceImages.length; i++) {
    console.log(
      `   üì∑ Analyse r√©f√©rence ${i + 1}/${referenceImages.length}...`
    );
    const refAnalysis = await analyzeReferenceImage(referenceImages[i]);
    referenceAnalyses.push(refAnalysis);
  }

  // 2. Contexte des zones (surfaces) identifi√©es
  const zonesContext = analysis.visibleZones
    .map(
      (z) =>
        `- SURFACE | ID: "${z.id}" | Nom: "${z.name}" | Type: ${
          z.elementType || "surface"
        } | Mat√©riau: ${z.currentMaterial}`
    )
    .join("\n");

  // 3. Contexte des objets identifi√©s
  const objectsContext = (analysis.visibleObjects || [])
    .map(
      (o) =>
        `- OBJET | ID: "${o.id}" | Nom: "${o.name}" | Cat√©gorie: ${o.category} | Style: ${o.style} | Position: ${o.position}`
    )
    .join("\n");

  // 4. Contexte des r√©f√©rences avec leur type
  const referencesContext = instructions
    .map((instr, i) => {
      const refAnalysis = referenceAnalyses[i];
      return `${i + 1}. Instruction: "${instr.location}"
     ‚Üí R√©f√©rence: ${instr.referenceName || "image " + (i + 1)}
     ‚Üí Type d√©tect√©: ${refAnalysis?.type?.toUpperCase() || "INCONNU"} (${
        refAnalysis?.category || "non analys√©"
      })
     ‚Üí Action: ${refAnalysis?.action || "apply_texture"}`;
    })
    .join("\n");

  const planningPrompt = `Tu es un expert en am√©nagement et d√©coration d'int√©rieur/ext√©rieur.

√âL√âMENTS IDENTIFI√âS DANS L'IMAGE ORIGINALE:

SURFACES (murs, sols, plafonds):
${zonesContext || "Aucune surface identifi√©e"}

OBJETS (meubles, luminaires, d√©co, plantes):
${objectsContext || "Aucun objet identifi√©"}

INSTRUCTIONS DE L'UTILISATEUR AVEC ANALYSE DES R√âF√âRENCES:
${referencesContext}

Ta mission: Cr√©er un plan de modification INTELLIGENT.

R√àGLES CRUCIALES:
1. Si la r√©f√©rence est un MAT√âRIAU ‚Üí action = "apply_texture" sur une SURFACE
2. Si la r√©f√©rence est un OBJET ‚Üí action = "replace_object" pour remplacer un objet similaire
3. Matcher la cat√©gorie de l'objet de r√©f√©rence avec les objets dans l'image
   - R√©f√©rence = table ‚Üí chercher les tables dans l'image
   - R√©f√©rence = lampe ‚Üí chercher les luminaires dans l'image
   - R√©f√©rence = plante ‚Üí chercher les plantes dans l'image

EXEMPLES:
- "table" + r√©f√©rence type OBJET (table moderne) ‚Üí replace_object sur table_dining
- "mur" + r√©f√©rence type MAT√âRIAU (peinture) ‚Üí apply_texture sur wall_*
- "luminaire" + r√©f√©rence type OBJET (lustre) ‚Üí replace_object sur lamp_ceiling

R√©ponds avec ce JSON (sans markdown):
{
  "mappings": [
    {
      "instructionIndex": 0,
      "action": "apply_texture | replace_object | add_element",
      "targetType": "surface | object",
      "targetIds": ["wall_left", "wall_right"],
      "interpretation": "Appliquer la peinture bleue sur les murs"
    },
    {
      "instructionIndex": 1,
      "action": "replace_object",
      "targetType": "object",
      "targetIds": ["table_dining"],
      "interpretation": "Remplacer la table actuelle par la table moderne de r√©f√©rence"
    }
  ],
  "warnings": []
}`;

  try {
    const response = await ai.models.generateContent({
      model: MODELS.ANALYZER,
      contents: [{ text: planningPrompt }],
    });

    const text = response.candidates?.[0]?.content?.parts?.[0]?.text || "";
    const jsonMatch = text.match(/\{[\s\S]*\}/);

    if (jsonMatch) {
      const mapping = JSON.parse(jsonMatch[0]);
      let tasks: ModificationTask[] = [];

      for (const m of mapping.mappings || []) {
        const instruction = instructions[m.instructionIndex];
        const refAnalysis = referenceAnalyses[m.instructionIndex];
        const actionType = m.action || refAnalysis?.action || "apply_texture";

        for (const targetId of m.targetIds || []) {
          if (m.targetType === "object" || actionType === "replace_object") {
            // C'est un remplacement d'objet
            const targetObj = (analysis.visibleObjects || []).find(
              (o) => o.id === targetId
            );
            if (targetObj) {
              tasks.push({
                priority: m.instructionIndex,
                targetObject: targetObj,
                targetMaterial:
                  instruction.referenceName ||
                  refAnalysis?.category ||
                  "objet de r√©f√©rence",
                referenceIndex: m.instructionIndex,
                specificInstructions: m.interpretation || instruction.location,
                actionType: "replace_object",
                referenceAnalysis: refAnalysis,
              });
            }
          } else {
            // C'est une application de mat√©riau sur surface
            const zone = analysis.visibleZones.find((z) => z.id === targetId);
            if (zone) {
              tasks.push({
                priority: m.instructionIndex,
                zone: zone,
                targetMaterial:
                  instruction.referenceName ||
                  refAnalysis?.category ||
                  "mat√©riau de r√©f√©rence",
                referenceIndex: m.instructionIndex,
                specificInstructions: m.interpretation || instruction.location,
                actionType: "apply_texture",
                referenceAnalysis: refAnalysis,
              });
            }
          }
        }
      }

      // R√©solution des conflits
      const elementAssignments = new Map<string, ModificationTask>();
      for (const task of tasks) {
        const id = task.zone?.id || task.targetObject?.id || "";
        const existing = elementAssignments.get(id);
        if (existing) {
          if (task.referenceIndex > existing.referenceIndex) {
            elementAssignments.set(id, task);
          }
        } else {
          elementAssignments.set(id, task);
        }
      }
      tasks = Array.from(elementAssignments.values());

      console.log(`\n   ‚úì ${tasks.length} t√¢ches de modification planifi√©es:`);
      for (const task of tasks) {
        const targetName = task.zone?.name || task.targetObject?.name || "?";
        const emoji = task.actionType === "replace_object" ? "üîÑ" : "üé®";
        console.log(
          `      ${emoji} ${task.actionType}: ${targetName} ‚Üí ${task.targetMaterial}`
        );
      }

      const globalPrompt = buildOptimizedPrompt(
        analysis,
        tasks,
        instructions,
        referenceAnalyses
      );
      return { originalAnalysis: analysis, tasks, globalPrompt };
    }
  } catch (error) {
    console.warn("   ‚ö†Ô∏è Planification √©chou√©e, utilisation du mapping direct");
  }

  // Fallback: mapping direct bas√© sur les mots-cl√©s et l'analyse de r√©f√©rence
  const tasks: ModificationTask[] = [];

  for (let i = 0; i < instructions.length; i++) {
    const instr = instructions[i];
    const location = instr.location.toLowerCase();
    const refAnalysis = referenceAnalyses[i];

    // D√©terminer le type d'action bas√© sur l'analyse de r√©f√©rence
    const actionType = refAnalysis?.action || "apply_texture";

    if (actionType === "replace_object" && analysis.visibleObjects) {
      // Chercher un objet correspondant
      const matchedObjects: ObjectInfo[] = [];
      for (const obj of analysis.visibleObjects) {
        const objLower = obj.name.toLowerCase();
        const catLower = obj.category.toLowerCase();

        // Matcher par cat√©gorie ou nom
        if (
          location.includes("table") &&
          (catLower.includes("table") || objLower.includes("table"))
        ) {
          matchedObjects.push(obj);
        } else if (
          location.includes("chaise") &&
          (catLower.includes("chaise") || catLower.includes("chair"))
        ) {
          matchedObjects.push(obj);
        } else if (
          location.includes("lampe") ||
          location.includes("luminaire") ||
          location.includes("lustre")
        ) {
          if (
            catLower.includes("lum") ||
            catLower.includes("lamp") ||
            catLower.includes("light")
          ) {
            matchedObjects.push(obj);
          }
        } else if (location.includes("plante")) {
          if (catLower.includes("plant") || catLower.includes("v√©g√©t")) {
            matchedObjects.push(obj);
          }
        } else if (location.includes("canap√©") || location.includes("sofa")) {
          if (
            catLower.includes("canap") ||
            catLower.includes("sofa") ||
            catLower.includes("fauteuil")
          ) {
            matchedObjects.push(obj);
          }
        }
      }

      for (const obj of matchedObjects) {
        tasks.push({
          priority: i,
          targetObject: obj,
          targetMaterial:
            instr.referenceName || refAnalysis?.category || "r√©f√©rence",
          referenceIndex: i,
          specificInstructions: instr.location,
          actionType: "replace_object",
          referenceAnalysis: refAnalysis,
        });
      }
    } else {
      // Application de mat√©riau sur surfaces
      const matchedZones: ZoneInfo[] = [];

      for (const zone of analysis.visibleZones) {
        const zoneLower = zone.name.toLowerCase();
        const zoneIdLower = zone.id.toLowerCase();

        if (
          location.includes("gauche") &&
          (zoneLower.includes("gauche") || zoneIdLower.includes("left"))
        ) {
          matchedZones.push(zone);
        } else if (
          location.includes("droit") &&
          (zoneLower.includes("droit") || zoneIdLower.includes("right"))
        ) {
          matchedZones.push(zone);
        } else if (
          (location.includes("fond") || location.includes("face")) &&
          (zoneLower.includes("fond") || zoneIdLower.includes("back"))
        ) {
          matchedZones.push(zone);
        } else if (
          location.includes("sol") &&
          (zoneLower.includes("sol") || zoneIdLower.includes("floor"))
        ) {
          matchedZones.push(zone);
        } else if (
          location.includes("plafond") &&
          (zoneLower.includes("plafond") || zoneIdLower.includes("ceiling"))
        ) {
          matchedZones.push(zone);
        } else if (
          location.includes("tous les murs") &&
          zoneIdLower.includes("wall")
        ) {
          matchedZones.push(zone);
        } else if (location.includes("mur") && zoneIdLower.includes("wall")) {
          matchedZones.push(zone);
        }
      }

      // Si aucune correspondance, utiliser la premi√®re zone
      if (matchedZones.length === 0) {
        const defaultZone =
          analysis.visibleZones.find(
            (z) => z.id.includes("wall") || z.id.includes("floor")
          ) || analysis.visibleZones[0];
        if (defaultZone) matchedZones.push(defaultZone);
      }

      for (const zone of matchedZones) {
        tasks.push({
          priority: i,
          zone: zone,
          targetMaterial:
            instr.referenceName || refAnalysis?.category || "r√©f√©rence",
          referenceIndex: i,
          specificInstructions: instr.location,
          actionType: "apply_texture",
          referenceAnalysis: refAnalysis,
        });
      }
    }
  }

  console.log(`   ‚úì ${tasks.length} t√¢ches (fallback)`);

  return {
    originalAnalysis: analysis,
    tasks,
    globalPrompt: buildOptimizedPrompt(
      analysis,
      tasks,
      instructions,
      referenceAnalyses
    ),
  };
}

// ============================================================================
// CONSTRUCTION DU PROMPT OPTIMIS√â (POLYVALENT: MAT√âRIAUX ET OBJETS)
// ============================================================================

function buildOptimizedPrompt(
  analysis: ImageAnalysis,
  tasks: ModificationTask[],
  instructions: GenerationInstruction[],
  referenceAnalyses?: ReferenceAnalysis[]
): string {
  // S√©parer les t√¢ches par type d'action
  const materialTasks = tasks.filter(
    (t) => t.actionType === "apply_texture" || !t.actionType
  );
  const objectTasks = tasks.filter((t) => t.actionType === "replace_object");
  const addTasks = tasks.filter((t) => t.actionType === "add_element");

  // Construire les blocs de modification par type
  const modificationBlocks: string[] = [];

  // BLOC 1: Applications de mat√©riaux sur surfaces
  if (materialTasks.length > 0) {
    modificationBlocks.push(`
## üé® MODIFICATIONS DE SURFACES (Application de mat√©riaux)
`);
    const groupedMaterials = new Map<number, ModificationTask[]>();
    for (const task of materialTasks) {
      if (!groupedMaterials.has(task.referenceIndex)) {
        groupedMaterials.set(task.referenceIndex, []);
      }
      groupedMaterials.get(task.referenceIndex)!.push(task);
    }

    groupedMaterials.forEach((zoneTasks, refIndex) => {
      const instruction = instructions[refIndex];
      const refAnalysis = referenceAnalyses?.[refIndex];
      const materialName =
        instruction.referenceName ||
        refAnalysis?.category ||
        "mat√©riau de r√©f√©rence";

      const zoneDescriptions = zoneTasks
        .map((t) => {
          if (t.zone) {
            return `   ‚Ä¢ **${t.zone.name}**: ${t.zone.description}
      - Limites: ${t.zone.boundaries}
      - Mat√©riau actuel: ${t.zone.currentMaterial}`;
          }
          return "";
        })
        .filter(Boolean)
        .join("\n");

      modificationBlocks.push(`
### SURFACE ${refIndex + 1}: Appliquer "${materialName}"
**Image de r√©f√©rence**: IMAGE ${refIndex + 2}
**Style**: ${refAnalysis?.style || "non sp√©cifi√©"} | **Couleur**: ${
        refAnalysis?.mainColor || "non sp√©cifi√©e"
      }

**Zones cibl√©es**:
${zoneDescriptions}

**Instructions**:
1. Examiner l'IMAGE ${
        refIndex + 2
      } pour comprendre: texture, couleur, motifs, reflets
2. APPLIQUER ce mat√©riau sur 100% de chaque surface list√©e
3. Aucune trace de l'ancien mat√©riau ne doit rester
4. Adapter les ombres et reflets √† l'√©clairage ambiant`);
    });
  }

  // BLOC 2: Remplacements d'objets
  if (objectTasks.length > 0) {
    modificationBlocks.push(`
## üîÑ REMPLACEMENTS D'OBJETS (Substitution compl√®te)
`);
    for (const task of objectTasks) {
      const instruction = instructions[task.referenceIndex];
      const refAnalysis = task.referenceAnalysis;
      const objectName =
        instruction.referenceName ||
        refAnalysis?.category ||
        "objet de r√©f√©rence";
      const targetObj = task.targetObject;

      modificationBlocks.push(`
### OBJET: Remplacer "${targetObj?.name || "objet"}" par "${objectName}"
**Image de r√©f√©rence**: IMAGE ${task.referenceIndex + 2}
**Type d'objet**: ${refAnalysis?.category || "meuble/d√©coration"}
**Style**: ${refAnalysis?.style || "non sp√©cifi√©"} | **Mati√®re**: ${
        refAnalysis?.material || "non sp√©cifi√©e"
      } | **Couleur**: ${refAnalysis?.mainColor || "non sp√©cifi√©e"}

**Objet √† remplacer**:
   ‚Ä¢ **${targetObj?.name || "Objet cible"}**
   - Cat√©gorie: ${targetObj?.category || "meuble"}
   - Position: ${targetObj?.position || "dans l'image"}
   - Style actuel: ${targetObj?.style || "non sp√©cifi√©"}

**Instructions CRITIQUES**:
1. SUPPRIMER COMPL√àTEMENT l'objet actuel (${targetObj?.name})
2. INS√âRER l'objet visible dans l'IMAGE ${
        task.referenceIndex + 2
      } √Ä LA M√äME POSITION
3. Conserver les M√äMES DIMENSIONS approximatives (adapter √† l'espace)
4. Adapter l'√©clairage et les ombres pour int√©gration r√©aliste
5. L'objet de remplacement doit respecter la perspective de la sc√®ne`);
    }
  }

  // BLOC 3: Ajouts d'√©l√©ments
  if (addTasks.length > 0) {
    modificationBlocks.push(`
## ‚ûï AJOUTS D'√âL√âMENTS (Nouveaux √©l√©ments)
`);
    for (const task of addTasks) {
      const instruction = instructions[task.referenceIndex];
      const refAnalysis = task.referenceAnalysis;
      const elementName =
        instruction.referenceName || refAnalysis?.category || "√©l√©ment";

      modificationBlocks.push(`
### AJOUT: Ins√©rer "${elementName}"
**Image de r√©f√©rence**: IMAGE ${task.referenceIndex + 2}
**Position demand√©e**: ${instruction.location}

**Instructions**:
1. Examiner l'√©l√©ment dans l'IMAGE ${task.referenceIndex + 2}
2. L'INS√âRER √† la position indiqu√©e
3. Adapter taille et perspective √† la sc√®ne
4. Int√©grer naturellement avec ombres appropri√©es`);
    }
  }

  // Construction du contexte des objets visibles
  const objectsListing = (analysis.visibleObjects || [])
    .map((o) => `   - ${o.name} (${o.category}) - ${o.position}`)
    .join("\n");

  return `# MISSION: TRANSFORMATION D'ESPACE PHOTOR√âALISTE

Tu es un moteur de rendu IA sp√©cialis√© en visualisation d'am√©nagement int√©rieur et ext√©rieur.
Tu peux r√©aliser TOUS types de modifications: changement de mat√©riaux, remplacement de meubles, ajout de d√©coration, modification de luminaires, ajout de plantes, etc.

## ANALYSE DE L'IMAGE ORIGINALE (IMAGE 1)
- **Type d'espace**: ${analysis.roomType}
- **√âclairage**: ${analysis.lighting}
- **Perspective cam√©ra**: ${analysis.perspective}

**Surfaces identifi√©es**: ${analysis.visibleZones.map((z) => z.name).join(", ")}

**Objets identifi√©s**:
${objectsListing || "   - Aucun objet sp√©cifique identifi√©"}

## IMAGES FOURNIES
- **IMAGE 1**: Photo originale de l'espace (AVANT transformation)
- **IMAGES 2, 3, ...**: √âl√©ments de R√âF√âRENCE (mat√©riaux OU objets √† utiliser)

${modificationBlocks.join("\n")}

## R√àGLES ABSOLUES

### POUR LES MAT√âRIAUX (surfaces):
- Appliquer la texture/couleur sur 100% de la surface indiqu√©e
- Aucune trace de l'ancien mat√©riau ne doit subsister
- Respecter la perspective et l'√©clairage existants

### POUR LES OBJETS (meubles, d√©co, luminaires, plantes):
- REMPLACER INT√âGRALEMENT l'objet existant par celui de la r√©f√©rence
- Conserver la M√äME POSITION dans l'espace
- Adapter les dimensions pour un rendu r√©aliste
- Int√©grer parfaitement avec ombres et reflets coh√©rents

### COH√âRENCE GLOBALE:
- Perspective IDENTIQUE √† l'image originale
- √âclairage coh√©rent sur tous les √©l√©ments
- Qualit√© photor√©aliste professionnelle

### NE PAS MODIFIER:
- Les √©l√©ments non mentionn√©s dans les instructions
- La structure architecturale (murs, plafond, fen√™tres) sauf si demand√©
- Les √©quipements techniques (prises, interrupteurs) sauf si demand√©

## ACTION FINALE
G√©n√®re UNE image photor√©aliste montrant l'espace APR√àS toutes les transformations demand√©es.`;
}

// ============================================================================
// AGENT 3: G√âN√âRATEUR D'IMAGE (NANO BANANA PRO)
// ============================================================================

async function generateWithNanoBanana(
  originalImage: { base64: string; mimeType: string },
  referenceImages: { base64: string; mimeType: string }[],
  prompt: string,
  outputDir: string,
  generationId: string
): Promise<{ imagePath: string; description: string }> {
  console.log(
    "   üé® Agent G√©n√©rateur: Appel √† Nano Banana Pro (gemini-3-pro-image-preview)..."
  );
  console.log(`   üìù Prompt: ${prompt.length} caract√®res`);
  console.log(
    `   üñºÔ∏è  Config: ${IMAGE_CONFIG.imageSize} @ ${IMAGE_CONFIG.aspectRatio}`
  );

  // Afficher le prompt complet pour debug
  console.log("\n" + "‚îÄ".repeat(70));
  console.log("üìù PROMPT COMPLET ENVOY√â √Ä GEMINI:");
  console.log("‚îÄ".repeat(70));
  console.log(prompt);
  console.log("‚îÄ".repeat(70) + "\n");

  // Construire le contenu selon la documentation officielle Nano Banana Pro
  // L'ordre est important: prompt texte d'abord, puis les images
  const contents: any[] = [
    { text: prompt },
    {
      inlineData: {
        mimeType: originalImage.mimeType,
        data: originalImage.base64,
      },
    },
  ];

  for (const refImage of referenceImages) {
    contents.push({
      inlineData: { mimeType: refImage.mimeType, data: refImage.base64 },
    });
  }

  console.log(`   üñºÔ∏è  ${1 + referenceImages.length} images envoy√©es`);

  // Appel avec configuration avanc√©e Nano Banana Pro
  const response = await ai.models.generateContent({
    model: MODELS.GENERATOR,
    contents: contents,
    config: {
      responseModalities: ["TEXT", "IMAGE"],
      imageConfig: {
        aspectRatio: IMAGE_CONFIG.aspectRatio,
        imageSize: IMAGE_CONFIG.imageSize,
      },
    },
  });

  if (!response.candidates || response.candidates.length === 0) {
    throw new Error("R√©ponse vide de l'API Gemini");
  }

  const parts = response.candidates[0].content?.parts || [];
  let generatedImagePath = "";
  let description = "";
  let thoughtCount = 0;

  // Traitement des parties (inclut les "thought" images de Nano Banana Pro)
  for (const part of parts) {
    // Ignorer les images de "thinking" (interm√©diaires)
    if ((part as any).thought) {
      thoughtCount++;
      continue;
    }

    if (part.inlineData?.data) {
      const imageData = part.inlineData.data;
      const mimeType = part.inlineData.mimeType || "image/png";
      const extension = mimeType.split("/")[1]?.replace("jpeg", "jpg") || "png";

      const fileName = `generated_${generationId}.${extension}`;
      const imageBuffer = Buffer.from(imageData as string, "base64");

      // Sauvegarder sur S3
      generatedImagePath = await saveBuffer(imageBuffer, fileName, "generated");

      console.log(
        `   üíæ Sauvegard√© sur S3: ${fileName} (${(
          imageBuffer.length / 1024
        ).toFixed(0)} KB)`
      );
      if (thoughtCount > 0) {
        console.log(
          `   üß† Mode Thinking: ${thoughtCount} image(s) interm√©diaire(s) g√©n√©r√©e(s)`
        );
      }
    } else if (part.text) {
      description = part.text;
    }
  }

  if (!generatedImagePath) {
    throw new Error(
      `Pas d'image g√©n√©r√©e. R√©ponse: ${
        description?.substring(0, 300) || "vide"
      }`
    );
  }

  return {
    imagePath: generatedImagePath,
    description: description || "Image g√©n√©r√©e avec succ√®s",
  };
}

// ============================================================================
// FONCTION PRINCIPALE: ORCHESTRATION AGENTIQUE
// ============================================================================

export async function generateBeforeAfter(
  originalImagePath: string,
  instructions: GenerationInstruction[],
  outputDir: string,
  generationId: string,
  options: GenerationOptions = {}
): Promise<GenerationResult> {
  const startTime = Date.now();

  console.log("\n" + "‚ïê".repeat(70));
  console.log("ü§ñ SYST√àME AGENTIQUE DE G√âN√âRATION AVANT/APR√àS");
  console.log("‚ïê".repeat(70));
  console.log(`üìã ${instructions.length} instruction(s) de l'utilisateur:`);
  console.log(`üÜî ID: ${generationId}`);
  console.log("");

  for (let i = 0; i < instructions.length; i++) {
    const instr = instructions[i];
    console.log(`   üìå Instruction ${i + 1}:`);
    console.log(`      ‚îî‚îÄ Emplacement: "${instr.location}"`);
    console.log(`      ‚îî‚îÄ Nom: ${instr.referenceName || "(sans nom)"}`);
    console.log(`      ‚îî‚îÄ Image: ${instr.referenceImagePath}`);
  }

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // CHARGEMENT DES IMAGES (les erreurs S3 seront g√©r√©es lors du chargement)
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  console.log("\nüì∏ Chargement des images...");
  const originalImage = await prepareImageForAPI(originalImagePath);
  console.log(
    `   ‚úì Original: ${(originalImage.base64.length / 1024).toFixed(0)} KB`
  );

  const referenceImages: { base64: string; mimeType: string }[] = [];
  for (let i = 0; i < instructions.length; i++) {
    const refImage = await prepareImageForAPI(
      instructions[i].referenceImagePath
    );
    referenceImages.push(refImage);
    console.log(
      `   ‚úì R√©f√©rence ${i + 1}: ${(refImage.base64.length / 1024).toFixed(
        0
      )} KB`
    );
  }

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // PHASE 1: ANALYSE AGENTIQUE
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  console.log("\nüî¨ PHASE 1: Analyse intelligente de l'image");
  console.log("‚îÄ".repeat(50));

  const analysis = await analyzeImageWithAgent(originalImage);

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // PHASE 2: PLANIFICATION DES MODIFICATIONS
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  console.log("\nüìä PHASE 2: Planification et mapping des zones");
  console.log("‚îÄ".repeat(50));

  const plan = await planModificationsWithAgent(
    analysis,
    instructions,
    referenceImages
  );

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // PHASE 3: G√âN√âRATION AVEC RETRY
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  console.log("\nüé® PHASE 3: G√©n√©ration de l'image");
  console.log("‚îÄ".repeat(50));

  let lastError: Error | null = null;

  for (let attempt = 1; attempt <= CONFIG.maxRetries; attempt++) {
    console.log(`\nüîÑ Tentative ${attempt}/${CONFIG.maxRetries}`);

    try {
      // Premier essai: prompt complet. Retries: prompt simplifi√©
      const prompt =
        attempt === 1
          ? plan.globalPrompt
          : buildSimplifiedRetryPrompt(instructions, plan.tasks, attempt);

      const result = await generateWithNanoBanana(
        originalImage,
        referenceImages,
        prompt,
        outputDir,
        generationId
      );

      const duration = ((Date.now() - startTime) / 1000).toFixed(1);

      console.log("\n" + "‚ïê".repeat(70));
      console.log("‚úÖ G√âN√âRATION R√âUSSIE!");
      console.log(`   üìÅ ${result.imagePath}`);
      console.log(`   ‚è±Ô∏è  Dur√©e: ${duration}s`);
      console.log(`   üî¢ Tentatives: ${attempt}`);
      console.log("‚ïê".repeat(70) + "\n");

      return {
        imagePath: result.imagePath,
        description: result.description,
        attempts: attempt,
        analysisDetails: analysis,
      };
    } catch (error) {
      lastError = error as Error;
      console.error(`   ‚ùå √âchec: ${lastError.message.substring(0, 200)}`);

      if (attempt < CONFIG.maxRetries) {
        const delay = Math.min(
          CONFIG.initialDelayMs *
            Math.pow(CONFIG.backoffMultiplier, attempt - 1),
          CONFIG.maxDelayMs
        );
        console.log(`   ‚è≥ Nouveau essai dans ${delay}ms...`);
        await sleep(delay);
      }
    }
  }

  throw new Error(
    `√âchec apr√®s ${CONFIG.maxRetries} tentatives. ${lastError?.message}`
  );
}

// ============================================================================
// FONCTION AVEC PROGRESS CALLBACK POUR STREAMING SSE
// ============================================================================

export type ProgressCallback = (event: {
  type: "log" | "step" | "error";
  icon?: string;
  message?: string;
  step?: string;
  status?: "pending" | "loading" | "done" | "error";
}) => void;

export async function generateBeforeAfterWithProgress(
  originalImagePath: string,
  instructions: GenerationInstruction[],
  outputDir: string,
  generationId: string,
  onProgress: ProgressCallback,
  options: GenerationOptions = {}
): Promise<GenerationResult> {
  const startTime = Date.now();

  const log = (icon: string, message: string) => {
    console.log(`${icon} ${message}`);
    onProgress({ type: "log", icon, message });
  };

  const setStep = (
    step: string,
    status: "pending" | "loading" | "done" | "error"
  ) => {
    onProgress({ type: "step", step, status });
  };

  log("ü§ñ", "SYST√àME AGENTIQUE DE G√âN√âRATION AVANT/APR√àS");
  log("üìã", `${instructions.length} instruction(s) de l'utilisateur`);
  log("üÜî", `ID: ${generationId}`);

  for (let i = 0; i < instructions.length; i++) {
    const instr = instructions[i];
    log(
      "üìå",
      `Instruction ${i + 1}: "${instr.location}" - ${
        instr.referenceName || "(sans nom)"
      }`
    );
  }

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // CHARGEMENT DES IMAGES
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  setStep("upload", "loading");
  log("üì∏", "Chargement des images depuis S3...");

  const originalImage = await prepareImageForAPI(originalImagePath);
  log("‚úì", `Original: ${(originalImage.base64.length / 1024).toFixed(0)} KB`);

  const referenceImages: { base64: string; mimeType: string }[] = [];
  for (let i = 0; i < instructions.length; i++) {
    const refImage = await prepareImageForAPI(
      instructions[i].referenceImagePath
    );
    referenceImages.push(refImage);
    log(
      "‚úì",
      `R√©f√©rence ${i + 1}: ${(refImage.base64.length / 1024).toFixed(0)} KB`
    );
  }

  setStep("upload", "done");

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // PHASE 1: ANALYSE AGENTIQUE
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  setStep("analyze", "loading");
  log("üî¨", "PHASE 1: Analyse intelligente de l'image");
  log("üß†", "Identification des √©l√©ments de la pi√®ce...");

  const analysis = await analyzeImageWithAgent(originalImage);

  log(
    "‚úì",
    `Analyse termin√©e: ${analysis.roomType} - ${
      analysis.visibleZones.length
    } surfaces, ${(analysis.visibleObjects || []).length} objets`
  );
  setStep("analyze", "done");

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // PHASE 2: PLANIFICATION DES MODIFICATIONS
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  setStep("plan", "loading");
  log("üìä", "PHASE 2: Planification et mapping des zones");
  log("üó∫Ô∏è", "Cr√©ation du plan de modification...");

  const plan = await planModificationsWithAgent(
    analysis,
    instructions,
    referenceImages
  );

  log("‚úì", `Plan cr√©√©: ${plan.tasks?.length || 0} t√¢che(s) de modification`);
  if (plan.tasks && plan.tasks.length > 0) {
    for (const task of plan.tasks) {
      const targetName = task.zone?.name || task.targetObject?.name || "Cible";
      const actionEmoji = task.actionType === "replace_object" ? "üîÑ" : "üé®";
      log(
        "üìç",
        `${actionEmoji} ${
          task.actionType
        }: ${targetName} ‚Üí ${task.targetMaterial.substring(0, 40)}`
      );
    }
  }
  setStep("plan", "done");

  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  // PHASE 3: G√âN√âRATION AVEC RETRY
  // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

  setStep("generate", "loading");
  log("üé®", "PHASE 3: G√©n√©ration de l'image avec Gemini");

  let lastError: Error | null = null;

  for (let attempt = 1; attempt <= CONFIG.maxRetries; attempt++) {
    log("üîÑ", `Tentative ${attempt}/${CONFIG.maxRetries}`);

    try {
      const prompt =
        attempt === 1
          ? plan.globalPrompt
          : buildSimplifiedRetryPrompt(instructions, plan.tasks, attempt);

      log("üìù", `Envoi du prompt (${prompt.length} caract√®res)...`);

      const result = await generateWithNanoBanana(
        originalImage,
        referenceImages,
        prompt,
        outputDir,
        generationId
      );

      const duration = ((Date.now() - startTime) / 1000).toFixed(1);

      setStep("generate", "done");
      log("‚úÖ", `G√âN√âRATION R√âUSSIE en ${duration}s!`);
      log("üìÅ", `Image sauvegard√©e: ${result.imagePath}`);

      return {
        imagePath: result.imagePath,
        description: result.description,
        attempts: attempt,
        analysisDetails: analysis,
      };
    } catch (error) {
      lastError = error as Error;
      log(
        "‚ùå",
        `√âchec: ${(lastError?.message || "Erreur inconnue").substring(0, 150)}`
      );

      if (attempt < CONFIG.maxRetries) {
        const delay = Math.min(
          CONFIG.initialDelayMs *
            Math.pow(CONFIG.backoffMultiplier, attempt - 1),
          CONFIG.maxDelayMs
        );
        log("‚è≥", `Nouveau essai dans ${delay}ms...`);
        await sleep(delay);
      }
    }
  }

  setStep("generate", "error");
  onProgress({
    type: "error",
    message: `√âchec apr√®s ${CONFIG.maxRetries} tentatives: ${lastError?.message}`,
  });

  throw new Error(
    `√âchec apr√®s ${CONFIG.maxRetries} tentatives. ${lastError?.message}`
  );
}

// Prompt simplifi√© pour les retries
function buildSimplifiedRetryPrompt(
  instructions: GenerationInstruction[],
  tasks: ModificationTask[],
  attempt: number
): string {
  const mods = instructions
    .map((instr, i) => {
      const relevantTasks = tasks.filter((t) => t.referenceIndex === i);
      const zones = relevantTasks
        .map((t) => t.zone?.name || t.targetObject?.name || "cible")
        .join(", ");
      const action =
        relevantTasks[0]?.actionType === "replace_object"
          ? "Remplacer par l'objet de"
          : "Appliquer le mat√©riau de";
      return `${i + 1}. Cibles: ${zones || instr.location}
   ${action} l'IMAGE ${i + 2}${
        instr.referenceName ? ` (${instr.referenceName})` : ""
      }`;
    })
    .join("\n\n");

  return `G√©n√®re une image APR√àS TRANSFORMATION bas√©e sur l'IMAGE 1.

MODIFICATIONS REQUISES:
${mods}

R√àGLES:
- Pour les MAT√âRIAUX: appliquer sur 100% de la surface
- Pour les OBJETS: remplacer int√©gralement l'objet existant
- Garder exactement la m√™me perspective
- Rendu photor√©aliste professionnel

G√©n√®re l'image maintenant.`;
}

// ============================================================================
// FONCTIONS UTILITAIRES EXPORT√âES
// ============================================================================

/**
 * Analyse une image pour identifier les zones modifiables (utilisable depuis l'UI)
 */
export async function analyzeImage(imagePath: string): Promise<string> {
  const imageData = await prepareImageForAPI(imagePath);

  const response = await ai.models.generateContent({
    model: MODELS.ANALYZER,
    contents: [
      {
        text: `Analyse cette image d'un espace et identifie TOUS les √©l√©ments modifiables.

Pour chaque √©l√©ment:
1. **Nom**: Description pr√©cise (ex: "Mur gauche", "Sol parquet")
2. **√âtat actuel**: Type de rev√™tement actuel
3. **Modifications possibles**: Alternatives (parquet, carrelage, peinture...)

Sois exhaustif.`,
      },
      { inlineData: { mimeType: imageData.mimeType, data: imageData.base64 } },
    ],
  });

  return (
    response.candidates?.[0]?.content?.parts?.[0]?.text ||
    "Analyse non disponible"
  );
}

/**
 * Valide une image de r√©f√©rence (mat√©riau)
 */
export async function validateReference(imagePath: string): Promise<{
  valid: boolean;
  material?: string;
  quality?: string;
  suggestions?: string;
}> {
  const imageData = await prepareImageForAPI(imagePath);

  const response = await ai.models.generateContent({
    model: MODELS.ANALYZER,
    contents: [
      {
        text: `Cette image doit servir de r√©f√©rence pour un mat√©riau.

R√©ponds avec ce JSON (sans markdown):
{
  "valid": true ou false,
  "material": "nom du mat√©riau identifi√©",
  "quality": "excellente", "bonne", "moyenne" ou "insuffisante",
  "suggestions": "conseils si qualit√© non excellente"
}`,
      },
      { inlineData: { mimeType: imageData.mimeType, data: imageData.base64 } },
    ],
  });

  try {
    const text = response.candidates?.[0]?.content?.parts?.[0]?.text || "";
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (jsonMatch) return JSON.parse(jsonMatch[0]);
  } catch (e) {
    console.warn("Parsing validation √©chou√©:", e);
  }

  return { valid: true, material: "Mat√©riau", quality: "inconnue" };
}
