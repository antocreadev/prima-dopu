import { GoogleGenAI } from "@google/genai";
import heicConvert from "heic-convert";
import sharp from "sharp";
import { getImageBuffer, saveBuffer } from "./storage";

// ============================================================================
// SYSTÃˆME AGENTIQUE STATE-OF-THE-ART POUR RÃ‰NOVATION AVANT/APRÃˆS
// ============================================================================
// Architecture Multi-Agent:
// 1. Agent Analyste (Gemini Flash) - Comprend l'image en profondeur
// 2. Agent Planificateur (Gemini Flash) - Mappe les instructions sur les zones
// 3. Agent GÃ©nÃ©rateur (Nano Banana) - GÃ©nÃ¨re l'image avec prÃ©cision
// ============================================================================

const ai = new GoogleGenAI({
  apiKey:
    import.meta.env.AI_GOOGLE_API_KEY || process.env.AI_GOOGLE_API_KEY || "",
});

// ModÃ¨les utilisÃ©s dans l'architecture agentique
const MODELS = {
  ANALYZER: "gemini-2.5-flash", // Agent analyste & planificateur (texte)
  GENERATOR: "gemini-3-pro-image-preview", // Nano Banana Pro - meilleure qualitÃ©, thinking, 4K
} as const;

// Configuration de gÃ©nÃ©ration d'image (Nano Banana Pro)
const IMAGE_CONFIG = {
  aspectRatio: "4:3" as const, // Aspect ratio pour photos de piÃ¨ces
  imageSize: "2K" as const, // RÃ©solution: "1K", "2K", ou "4K"
} as const;

// Configuration robuste avec retry
const CONFIG = {
  maxRetries: 3,
  initialDelayMs: 2000,
  maxDelayMs: 15000,
  backoffMultiplier: 2,
  maxImageSizeBytes: 4 * 1024 * 1024,
};

// ============================================================================
// TYPES & INTERFACES
// ============================================================================

export type ModificationType =
  | "floor"
  | "wall"
  | "ceiling"
  | "furniture"
  | "add_element"
  | "facade"
  | "outdoor"
  | "custom";

export interface GenerationInstruction {
  location: string;
  referenceImagePath: string;
  referenceName?: string;
  modificationType?: ModificationType;
  additionalDetails?: string;
}

export interface GenerationResult {
  imagePath: string;
  description: string;
  attempts: number;
  analysisDetails?: ImageAnalysis;
}

export interface GenerationOptions {
  aspectRatio?: "1:1" | "3:4" | "4:3" | "9:16" | "16:9";
}

// RÃ©sultat de l'analyse agentique de l'image
interface ImageAnalysis {
  roomType: string;
  visibleZones: ZoneInfo[];
  lighting: string;
  perspective: string;
  existingMaterials: MaterialInfo[];
}

interface ZoneInfo {
  id: string;
  name: string;
  description: string;
  boundaries: string;
  currentMaterial: string;
}

interface MaterialInfo {
  zone: string;
  type: string;
  color: string;
  texture: string;
}

// Plan de modification gÃ©nÃ©rÃ© par l'agent planificateur
interface ModificationPlan {
  originalAnalysis: ImageAnalysis;
  tasks: ModificationTask[];
  globalPrompt: string;
}

interface ModificationTask {
  priority: number;
  zone: ZoneInfo;
  targetMaterial: string;
  referenceIndex: number;
  specificInstructions: string;
}

// ============================================================================
// UTILITAIRES
// ============================================================================

// Formats Apple nÃ©cessitant une conversion
const APPLE_FORMATS = ["heic", "heif", "hif"];

function getMimeType(filePath: string): string {
  const ext = filePath.toLowerCase().split(".").pop();
  const mimeTypes: Record<string, string> = {
    jpg: "image/jpeg",
    jpeg: "image/jpeg",
    png: "image/png",
    gif: "image/gif",
    webp: "image/webp",
  };
  return mimeTypes[ext || ""] || "image/jpeg";
}

async function sleep(ms: number): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

/**
 * PrÃ©pare une image pour l'API Gemini
 * - Lit l'image depuis S3
 * - Convertit les formats Apple (HEIC, HEIF) en JPEG via heic-convert
 * - Optimise les images trop volumineuses (>4MB) via sharp
 */
async function prepareImageForAPI(
  imagePath: string
): Promise<{ base64: string; mimeType: string }> {
  const ext = imagePath.toLowerCase().split(".").pop() || "";
  let buffer: Buffer = await getImageBuffer(imagePath);
  let mimeType = getMimeType(imagePath);

  // Conversion des formats Apple (HEIC, HEIF) avec heic-convert
  if (APPLE_FORMATS.includes(ext)) {
    console.log(`   ğŸ”„ Conversion ${ext.toUpperCase()} â†’ JPEG pour API...`);
    try {
      const converted = await heicConvert({
        buffer: buffer,
        format: "JPEG",
        quality: 0.9,
      });
      buffer = Buffer.from(converted);
      mimeType = "image/jpeg";
      console.log(
        `   âœ“ Converti pour API: ${(buffer.length / 1024).toFixed(0)} KB`
      );
    } catch (error) {
      console.error(`   âŒ Erreur conversion ${ext}:`, error);
      throw new Error(
        `Impossible de convertir ${ext.toUpperCase()}. Format non supportÃ©.`
      );
    }
  }

  // Optimisation si l'image est trop volumineuse (>4MB) avec sharp
  if (buffer.length > CONFIG.maxImageSizeBytes) {
    console.log(
      `   ğŸ“ Image trop volumineuse (${(buffer.length / 1024 / 1024).toFixed(
        1
      )}MB), optimisation...`
    );
    try {
      // RÃ©duire la qualitÃ© et/ou les dimensions
      buffer = Buffer.from(
        await sharp(buffer)
          .resize(2048, 2048, { fit: "inside", withoutEnlargement: true })
          .jpeg({ quality: 85 })
          .toBuffer()
      );
      mimeType = "image/jpeg";
      console.log(`   âœ“ OptimisÃ©: ${(buffer.length / 1024).toFixed(0)} KB`);
    } catch (error) {
      console.warn(
        `   âš ï¸ Optimisation Ã©chouÃ©e, utilisation de l'image originale`
      );
    }
  }

  return { base64: buffer.toString("base64"), mimeType };
}

// ============================================================================
// AGENT 1: ANALYSTE D'IMAGE (Gemini Flash - Texte)
// ============================================================================
// Analyse l'image en profondeur pour identifier toutes les zones modifiables

async function analyzeImageWithAgent(imageData: {
  base64: string;
  mimeType: string;
}): Promise<ImageAnalysis> {
  console.log("   ğŸ” Agent Analyste: Analyse intelligente de l'image...");

  const analysisPrompt = `Tu es un expert en architecture et rÃ©novation d'intÃ©rieur/extÃ©rieur.
Analyse cette image de maniÃ¨re EXHAUSTIVE pour identifier TOUTES les surfaces modifiables.

RÃ©ponds UNIQUEMENT avec ce JSON valide (sans markdown, sans backticks):
{
  "roomType": "type d'espace (salon, chambre, cuisine, terrasse, faÃ§ade...)",
  "visibleZones": [
    {
      "id": "wall_left",
      "name": "Mur de gauche",
      "description": "Mur vertical situÃ© sur le cÃ´tÃ© gauche de l'image",
      "boundaries": "Du coin infÃ©rieur gauche jusqu'au plafond, de la porte au coin",
      "currentMaterial": "Peinture blanche mate"
    },
    {
      "id": "wall_right", 
      "name": "Mur de droite",
      "description": "Mur vertical situÃ© sur le cÃ´tÃ© droit de l'image",
      "boundaries": "Du coin droit jusqu'Ã  la fenÃªtre",
      "currentMaterial": "Peinture blanche"
    },
    {
      "id": "wall_back",
      "name": "Mur du fond",
      "description": "Mur face Ã  la camÃ©ra",
      "boundaries": "Mur entier visible entre les murs latÃ©raux",
      "currentMaterial": "Peinture beige"
    },
    {
      "id": "floor_main",
      "name": "Sol",
      "description": "Surface horizontale au sol",
      "boundaries": "Toute la surface visible du sol",
      "currentMaterial": "Parquet bois clair"
    }
  ],
  "lighting": "LumiÃ¨re naturelle venant de la fenÃªtre Ã  droite, Ã©clairage doux",
  "perspective": "Vue en lÃ©gÃ¨re plongÃ©e depuis l'entrÃ©e de la piÃ¨ce",
  "existingMaterials": [
    {"zone": "Sol", "type": "parquet", "color": "chÃªne clair", "texture": "bois veinÃ©"}
  ]
}

RÃˆGLES D'IDENTIFICATION:
- Identifie CHAQUE mur visible sÃ©parÃ©ment (gauche, droite, fond, etc.)
- Identifie le sol en entier
- Identifie le plafond si visible
- Utilise des IDs uniques: wall_left, wall_right, wall_back, floor_main, ceiling, etc.
- Sois PRÃ‰CIS sur les dÃ©limitations physiques de chaque zone`;

  try {
    const response = await ai.models.generateContent({
      model: MODELS.ANALYZER,
      contents: [
        { text: analysisPrompt },
        {
          inlineData: { mimeType: imageData.mimeType, data: imageData.base64 },
        },
      ],
    });

    const text = response.candidates?.[0]?.content?.parts?.[0]?.text || "";

    // Extraire le JSON
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      const analysis = JSON.parse(jsonMatch[0]) as ImageAnalysis;
      console.log(`   âœ“ Type: ${analysis.roomType}`);
      console.log(`   âœ“ ${analysis.visibleZones.length} zones identifiÃ©es:`);
      for (const zone of analysis.visibleZones) {
        console.log(
          `      - ${zone.name} (${zone.id}): ${zone.currentMaterial}`
        );
      }
      return analysis;
    }
  } catch (error) {
    console.warn("   âš ï¸ Parsing de l'analyse Ã©chouÃ©, utilisation du fallback");
  }

  // Fallback avec des zones gÃ©nÃ©riques
  return {
    roomType: "espace intÃ©rieur",
    visibleZones: [
      {
        id: "wall_left",
        name: "Mur gauche",
        description: "Mur cÃ´tÃ© gauche",
        boundaries: "gauche de l'image",
        currentMaterial: "inconnu",
      },
      {
        id: "wall_right",
        name: "Mur droit",
        description: "Mur cÃ´tÃ© droit",
        boundaries: "droite de l'image",
        currentMaterial: "inconnu",
      },
      {
        id: "wall_back",
        name: "Mur du fond",
        description: "Mur face",
        boundaries: "fond de l'image",
        currentMaterial: "inconnu",
      },
      {
        id: "floor_main",
        name: "Sol",
        description: "Surface au sol",
        boundaries: "partie basse",
        currentMaterial: "inconnu",
      },
    ],
    lighting: "Ã©clairage standard",
    perspective: "vue frontale",
    existingMaterials: [],
  };
}

// ============================================================================
// AGENT 2: PLANIFICATEUR (Gemini Flash - Texte)
// ============================================================================
// InterprÃ¨te les instructions utilisateur et les mappe sur les zones identifiÃ©es

async function planModificationsWithAgent(
  analysis: ImageAnalysis,
  instructions: GenerationInstruction[],
  referenceImages: { base64: string; mimeType: string }[]
): Promise<ModificationPlan> {
  console.log("   ğŸ“‹ Agent Planificateur: Mapping des instructions...");

  // Contexte des zones identifiÃ©es
  const zonesContext = analysis.visibleZones
    .map(
      (z) =>
        `- ID: "${z.id}" | Nom: "${z.name}" | Description: ${z.description} | Limites: ${z.boundaries}`
    )
    .join("\n");

  // Contexte des instructions utilisateur
  const instructionsContext = instructions
    .map(
      (instr, i) =>
        `${i + 1}. Instruction: "${instr.location}" â†’ Appliquer: ${
          instr.referenceName || "rÃ©fÃ©rence " + (i + 1)
        }`
    )
    .join("\n");

  const planningPrompt = `Tu es un expert en interprÃ©tation d'instructions de rÃ©novation.

ZONES IDENTIFIÃ‰ES DANS L'IMAGE:
${zonesContext}

INSTRUCTIONS DE L'UTILISATEUR:
${instructionsContext}

Ta mission: Mapper PRÃ‰CISÃ‰MENT chaque instruction utilisateur sur les zones identifiÃ©es.

ATTENTION - RÃˆGLES CRITIQUES DE PRIORITÃ‰:
1. CHAQUE ZONE NE PEUT ÃŠTRE ASSIGNÃ‰E QU'Ã€ UNE SEULE INSTRUCTION
2. Les instructions SPÃ‰CIFIQUES ont PRIORITÃ‰ sur les instructions GÃ‰NÃ‰RIQUES
   - "crÃ©dence" est SPÃ‰CIFIQUE â†’ assigner UNIQUEMENT Ã  la crÃ©dence
   - "mur" est GÃ‰NÃ‰RIQUE â†’ assigner aux murs SAUF crÃ©dence
   - "sol" est SPÃ‰CIFIQUE â†’ assigner uniquement au sol
3. Si l'utilisateur donne une instruction pour "crÃ©dence" ET une pour "mur":
   - La crÃ©dence va Ã  l'instruction "crÃ©dence"
   - Les murs (sans la crÃ©dence) vont Ã  l'instruction "mur"

RÃ©ponds avec ce JSON (sans markdown):
{
  "mappings": [
    {
      "instructionIndex": 0,
      "targetZoneIds": ["wall_left", "wall_right"],
      "interpretation": "Explication du mapping",
      "coverage": "Description de la couverture"
    }
  ],
  "warnings": ["zone X en conflit, prioritÃ© donnÃ©e Ã  instruction Y"],
  "conflicts_resolved": [
    {"zone": "credence", "kept_instruction": 4, "removed_from": [3]}
  ]
}

RÃˆGLES DE MAPPING:
- "mur" sans prÃ©cision â†’ TOUS les murs (wall_*) SAUF crÃ©dence/splashback
- "crÃ©dence" ou "credence" â†’ UNIQUEMENT les zones splashback/tiled/credence
- "sol" â†’ ["floor_main"]
- "meuble" ou "cuisine" â†’ zones cabinet/furniture
- "Ã©vier" â†’ zones sink/countertop`;

  try {
    const response = await ai.models.generateContent({
      model: MODELS.ANALYZER,
      contents: [{ text: planningPrompt }],
    });

    const text = response.candidates?.[0]?.content?.parts?.[0]?.text || "";
    const jsonMatch = text.match(/\{[\s\S]*\}/);

    if (jsonMatch) {
      const mapping = JSON.parse(jsonMatch[0]);

      // Construire les tÃ¢ches
      let tasks: ModificationTask[] = [];

      for (const m of mapping.mappings || []) {
        const instruction = instructions[m.instructionIndex];

        for (const zoneId of m.targetZoneIds || []) {
          const zone = analysis.visibleZones.find((z) => z.id === zoneId);
          if (zone) {
            tasks.push({
              priority: m.instructionIndex,
              zone: zone,
              targetMaterial: instruction.referenceName || "image de rÃ©fÃ©rence",
              referenceIndex: m.instructionIndex,
              specificInstructions: m.coverage || instruction.location,
            });
          }
        }
      }

      // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      // RÃ‰SOLUTION DES CONFLITS DE ZONES
      // Une zone ne peut avoir qu'UN SEUL matÃ©riau - on garde la derniÃ¨re instruction
      // (l'utilisateur qui dit "crÃ©dence" aprÃ¨s "mur" veut que crÃ©dence gagne)
      // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      const zoneAssignments = new Map<string, ModificationTask>();
      const conflicts: string[] = [];

      for (const task of tasks) {
        const existing = zoneAssignments.get(task.zone.id);
        if (existing) {
          // Conflit dÃ©tectÃ©! La derniÃ¨re instruction (index plus Ã©levÃ©) gagne
          if (task.referenceIndex > existing.referenceIndex) {
            conflicts.push(
              `Zone "${task.zone.name}": "${existing.targetMaterial}" remplacÃ© par "${task.targetMaterial}"`
            );
            zoneAssignments.set(task.zone.id, task);
          } else {
            conflicts.push(
              `Zone "${task.zone.name}": "${task.targetMaterial}" ignorÃ©, "${existing.targetMaterial}" conservÃ©`
            );
          }
        } else {
          zoneAssignments.set(task.zone.id, task);
        }
      }

      // Reconstruire la liste de tÃ¢ches sans doublons
      tasks = Array.from(zoneAssignments.values());

      console.log(
        `   âœ“ ${tasks.length} tÃ¢ches de modification (aprÃ¨s rÃ©solution conflits):`
      );
      for (const task of tasks) {
        console.log(
          `      - ${task.zone.name} â†’ ${task.targetMaterial} [RÃ©f ${
            task.referenceIndex + 1
          }]`
        );
      }

      if (conflicts.length > 0) {
        console.log(`   âš ï¸ ${conflicts.length} conflit(s) de zone rÃ©solu(s):`);
        for (const c of conflicts) {
          console.log(`      ${c}`);
        }
      }

      if (mapping.warnings?.length > 0) {
        for (const w of mapping.warnings) {
          console.log(`   âš ï¸ ${w}`);
        }
      }

      // GÃ©nÃ©rer le prompt optimisÃ©
      const globalPrompt = buildOptimizedPrompt(analysis, tasks, instructions);

      return { originalAnalysis: analysis, tasks, globalPrompt };
    }
  } catch (error) {
    console.warn("   âš ï¸ Planification Ã©chouÃ©e, utilisation du mapping direct");
  }

  // Fallback: mapping direct basÃ© sur les mots-clÃ©s
  const tasks: ModificationTask[] = [];

  for (let i = 0; i < instructions.length; i++) {
    const instr = instructions[i];
    const location = instr.location.toLowerCase();

    // Mapping par mots-clÃ©s
    const matchedZones: ZoneInfo[] = [];

    for (const zone of analysis.visibleZones) {
      const zoneLower = zone.name.toLowerCase();
      const zoneIdLower = zone.id.toLowerCase();

      // VÃ©rifier si la zone correspond
      if (
        location.includes("gauche") &&
        (zoneLower.includes("gauche") || zoneIdLower.includes("left"))
      ) {
        matchedZones.push(zone);
      } else if (
        location.includes("droit") &&
        (zoneLower.includes("droit") || zoneIdLower.includes("right"))
      ) {
        matchedZones.push(zone);
      } else if (
        (location.includes("fond") || location.includes("face")) &&
        (zoneLower.includes("fond") || zoneIdLower.includes("back"))
      ) {
        matchedZones.push(zone);
      } else if (
        location.includes("sol") &&
        (zoneLower.includes("sol") || zoneIdLower.includes("floor"))
      ) {
        matchedZones.push(zone);
      } else if (
        location.includes("plafond") &&
        (zoneLower.includes("plafond") || zoneIdLower.includes("ceiling"))
      ) {
        matchedZones.push(zone);
      } else if (
        location.includes("tous les murs") &&
        zoneIdLower.includes("wall")
      ) {
        matchedZones.push(zone);
      }
    }

    // Si aucune correspondance, utiliser la premiÃ¨re zone de type mur ou sol
    if (matchedZones.length === 0) {
      const defaultZone =
        analysis.visibleZones.find(
          (z) => z.id.includes("wall") || z.id.includes("floor")
        ) || analysis.visibleZones[0];
      if (defaultZone) matchedZones.push(defaultZone);
    }

    for (const zone of matchedZones) {
      tasks.push({
        priority: i,
        zone: zone,
        targetMaterial: instr.referenceName || "rÃ©fÃ©rence",
        referenceIndex: i,
        specificInstructions: instr.location,
      });
    }
  }

  console.log(`   âœ“ ${tasks.length} tÃ¢ches (fallback)`);

  return {
    originalAnalysis: analysis,
    tasks,
    globalPrompt: buildOptimizedPrompt(analysis, tasks, instructions),
  };
}

// ============================================================================
// CONSTRUCTION DU PROMPT OPTIMISÃ‰ (BEST PRACTICES NANO BANANA)
// ============================================================================

function buildOptimizedPrompt(
  analysis: ImageAnalysis,
  tasks: ModificationTask[],
  instructions: GenerationInstruction[]
): string {
  // Grouper les tÃ¢ches par rÃ©fÃ©rence
  const groupedTasks = new Map<number, ModificationTask[]>();
  for (const task of tasks) {
    if (!groupedTasks.has(task.referenceIndex)) {
      groupedTasks.set(task.referenceIndex, []);
    }
    groupedTasks.get(task.referenceIndex)!.push(task);
  }

  // Construire les blocs de modification
  const modificationBlocks: string[] = [];

  groupedTasks.forEach((zoneTasks, refIndex) => {
    const instruction = instructions[refIndex];
    const materialName = instruction.referenceName || "image de rÃ©fÃ©rence";

    const zoneDescriptions = zoneTasks
      .map(
        (t) =>
          `â€¢ **${t.zone.name}**: ${t.zone.description}
        Limites: ${t.zone.boundaries}
        MatÃ©riau actuel: ${t.zone.currentMaterial}`
      )
      .join("\n");

    modificationBlocks.push(`
### MODIFICATION ${refIndex + 1}: Appliquer "${materialName}"
**Image de rÃ©fÃ©rence**: IMAGE ${refIndex + 2}

**Zones Ã  modifier**:
${zoneDescriptions}

**Instructions d'application**:
1. Examiner attentivement l'IMAGE ${
      refIndex + 2
    } pour comprendre: texture, couleur, motifs, brillance
2. Appliquer ce matÃ©riau sur CHAQUE zone listÃ©e ci-dessus
3. Couvrir 100% de chaque surface - aucune zone ne doit garder l'ancien matÃ©riau
4. Respecter le sens de pose naturel du matÃ©riau
5. Adapter les ombres et reflets selon l'Ã©clairage (${analysis.lighting})`);
  });

  return `# MISSION: VISUALISATION PROFESSIONNELLE APRÃˆS RÃ‰NOVATION

Tu es un moteur de rendu photorÃ©aliste de niveau professionnel pour le secteur BTP.
Tu gÃ©nÃ¨res UNE image montrant l'espace APRÃˆS les modifications demandÃ©es.

## ANALYSE DE L'IMAGE ORIGINALE (IMAGE 1)
- **Type d'espace**: ${analysis.roomType}
- **Ã‰clairage**: ${analysis.lighting}
- **Perspective camÃ©ra**: ${analysis.perspective}
- **Zones identifiÃ©es**: ${analysis.visibleZones.map((z) => z.name).join(", ")}

## IMAGES FOURNIES
- **IMAGE 1**: Photo originale AVANT rÃ©novation (l'espace Ã  transformer)
- **IMAGES 2, 3, ...**: Ã‰chantillons de matÃ©riaux de RÃ‰FÃ‰RENCE

## MODIFICATIONS Ã€ EFFECTUER
${modificationBlocks.join("\n")}

## RÃˆGLES CRITIQUES Ã€ RESPECTER

### 1. COUVERTURE INTÃ‰GRALE
Pour CHAQUE zone mentionnÃ©e dans les modifications:
- Appliquer le nouveau matÃ©riau sur 100% de la surface
- Aucune trace de l'ancien matÃ©riau ne doit rester visible
- Couvrir du bord Ã  bord, des limites indiquÃ©es

### 2. COHÃ‰RENCE GÃ‰OMÃ‰TRIQUE
- Perspective IDENTIQUE Ã  l'image originale (mÃªme angle de camÃ©ra)
- Proportions et dimensions prÃ©servÃ©es
- Lignes de fuite cohÃ©rentes

### 3. RÃ‰ALISME DES MATÃ‰RIAUX
- Reproduire fidÃ¨lement la texture visible dans chaque image de rÃ©fÃ©rence
- Adapter les reflets et ombres Ã  l'Ã©clairage existant
- Transitions naturelles aux bords et coins

### 4. PRÃ‰SERVATION STRICTE
Ne PAS modifier les Ã©lÃ©ments suivants:
- Portes, fenÃªtres, poignÃ©es
- Prises Ã©lectriques, interrupteurs
- Meubles (sauf si explicitement demandÃ©)
- Tous Ã©lÃ©ments non mentionnÃ©s dans les modifications

## ACTION
GÃ©nÃ¨re maintenant l'image photorÃ©aliste de l'espace APRÃˆS rÃ©novation avec TOUTES les modifications appliquÃ©es.`;
}

// ============================================================================
// AGENT 3: GÃ‰NÃ‰RATEUR D'IMAGE (NANO BANANA PRO)
// ============================================================================

async function generateWithNanoBanana(
  originalImage: { base64: string; mimeType: string },
  referenceImages: { base64: string; mimeType: string }[],
  prompt: string,
  outputDir: string,
  generationId: string
): Promise<{ imagePath: string; description: string }> {
  console.log(
    "   ğŸ¨ Agent GÃ©nÃ©rateur: Appel Ã  Nano Banana Pro (gemini-3-pro-image-preview)..."
  );
  console.log(`   ğŸ“ Prompt: ${prompt.length} caractÃ¨res`);
  console.log(
    `   ğŸ–¼ï¸  Config: ${IMAGE_CONFIG.imageSize} @ ${IMAGE_CONFIG.aspectRatio}`
  );

  // Afficher le prompt complet pour debug
  console.log("\n" + "â”€".repeat(70));
  console.log("ğŸ“ PROMPT COMPLET ENVOYÃ‰ Ã€ GEMINI:");
  console.log("â”€".repeat(70));
  console.log(prompt);
  console.log("â”€".repeat(70) + "\n");

  // Construire le contenu selon la documentation officielle Nano Banana Pro
  // L'ordre est important: prompt texte d'abord, puis les images
  const contents: any[] = [
    { text: prompt },
    {
      inlineData: {
        mimeType: originalImage.mimeType,
        data: originalImage.base64,
      },
    },
  ];

  for (const refImage of referenceImages) {
    contents.push({
      inlineData: { mimeType: refImage.mimeType, data: refImage.base64 },
    });
  }

  console.log(`   ğŸ–¼ï¸  ${1 + referenceImages.length} images envoyÃ©es`);

  // Appel avec configuration avancÃ©e Nano Banana Pro
  const response = await ai.models.generateContent({
    model: MODELS.GENERATOR,
    contents: contents,
    config: {
      responseModalities: ["TEXT", "IMAGE"],
      imageConfig: {
        aspectRatio: IMAGE_CONFIG.aspectRatio,
        imageSize: IMAGE_CONFIG.imageSize,
      },
    },
  });

  if (!response.candidates || response.candidates.length === 0) {
    throw new Error("RÃ©ponse vide de l'API Gemini");
  }

  const parts = response.candidates[0].content?.parts || [];
  let generatedImagePath = "";
  let description = "";
  let thoughtCount = 0;

  // Traitement des parties (inclut les "thought" images de Nano Banana Pro)
  for (const part of parts) {
    // Ignorer les images de "thinking" (intermÃ©diaires)
    if ((part as any).thought) {
      thoughtCount++;
      continue;
    }

    if (part.inlineData?.data) {
      const imageData = part.inlineData.data;
      const mimeType = part.inlineData.mimeType || "image/png";
      const extension = mimeType.split("/")[1]?.replace("jpeg", "jpg") || "png";

      const fileName = `generated_${generationId}.${extension}`;
      const imageBuffer = Buffer.from(imageData as string, "base64");

      // Sauvegarder sur S3
      generatedImagePath = await saveBuffer(imageBuffer, fileName, "generated");

      console.log(
        `   ğŸ’¾ SauvegardÃ© sur S3: ${fileName} (${(
          imageBuffer.length / 1024
        ).toFixed(0)} KB)`
      );
      if (thoughtCount > 0) {
        console.log(
          `   ğŸ§  Mode Thinking: ${thoughtCount} image(s) intermÃ©diaire(s) gÃ©nÃ©rÃ©e(s)`
        );
      }
    } else if (part.text) {
      description = part.text;
    }
  }

  if (!generatedImagePath) {
    throw new Error(
      `Pas d'image gÃ©nÃ©rÃ©e. RÃ©ponse: ${
        description?.substring(0, 300) || "vide"
      }`
    );
  }

  return {
    imagePath: generatedImagePath,
    description: description || "Image gÃ©nÃ©rÃ©e avec succÃ¨s",
  };
}

// ============================================================================
// FONCTION PRINCIPALE: ORCHESTRATION AGENTIQUE
// ============================================================================

export async function generateBeforeAfter(
  originalImagePath: string,
  instructions: GenerationInstruction[],
  outputDir: string,
  generationId: string,
  options: GenerationOptions = {}
): Promise<GenerationResult> {
  const startTime = Date.now();

  console.log("\n" + "â•".repeat(70));
  console.log("ğŸ¤– SYSTÃˆME AGENTIQUE DE GÃ‰NÃ‰RATION AVANT/APRÃˆS");
  console.log("â•".repeat(70));
  console.log(`ğŸ“‹ ${instructions.length} instruction(s) de l'utilisateur:`);
  console.log(`ğŸ†” ID: ${generationId}`);
  console.log("");

  for (let i = 0; i < instructions.length; i++) {
    const instr = instructions[i];
    console.log(`   ğŸ“Œ Instruction ${i + 1}:`);
    console.log(`      â””â”€ Emplacement: "${instr.location}"`);
    console.log(`      â””â”€ Nom: ${instr.referenceName || "(sans nom)"}`);
    console.log(`      â””â”€ Image: ${instr.referenceImagePath}`);
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // CHARGEMENT DES IMAGES (les erreurs S3 seront gÃ©rÃ©es lors du chargement)
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  console.log("\nğŸ“¸ Chargement des images...");
  const originalImage = await prepareImageForAPI(originalImagePath);
  console.log(
    `   âœ“ Original: ${(originalImage.base64.length / 1024).toFixed(0)} KB`
  );

  const referenceImages: { base64: string; mimeType: string }[] = [];
  for (let i = 0; i < instructions.length; i++) {
    const refImage = await prepareImageForAPI(
      instructions[i].referenceImagePath
    );
    referenceImages.push(refImage);
    console.log(
      `   âœ“ RÃ©fÃ©rence ${i + 1}: ${(refImage.base64.length / 1024).toFixed(
        0
      )} KB`
    );
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PHASE 1: ANALYSE AGENTIQUE
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  console.log("\nğŸ”¬ PHASE 1: Analyse intelligente de l'image");
  console.log("â”€".repeat(50));

  const analysis = await analyzeImageWithAgent(originalImage);

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PHASE 2: PLANIFICATION DES MODIFICATIONS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  console.log("\nğŸ“Š PHASE 2: Planification et mapping des zones");
  console.log("â”€".repeat(50));

  const plan = await planModificationsWithAgent(
    analysis,
    instructions,
    referenceImages
  );

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PHASE 3: GÃ‰NÃ‰RATION AVEC RETRY
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  console.log("\nğŸ¨ PHASE 3: GÃ©nÃ©ration de l'image");
  console.log("â”€".repeat(50));

  let lastError: Error | null = null;

  for (let attempt = 1; attempt <= CONFIG.maxRetries; attempt++) {
    console.log(`\nğŸ”„ Tentative ${attempt}/${CONFIG.maxRetries}`);

    try {
      // Premier essai: prompt complet. Retries: prompt simplifiÃ©
      const prompt =
        attempt === 1
          ? plan.globalPrompt
          : buildSimplifiedRetryPrompt(instructions, plan.tasks, attempt);

      const result = await generateWithNanoBanana(
        originalImage,
        referenceImages,
        prompt,
        outputDir,
        generationId
      );

      const duration = ((Date.now() - startTime) / 1000).toFixed(1);

      console.log("\n" + "â•".repeat(70));
      console.log("âœ… GÃ‰NÃ‰RATION RÃ‰USSIE!");
      console.log(`   ğŸ“ ${result.imagePath}`);
      console.log(`   â±ï¸  DurÃ©e: ${duration}s`);
      console.log(`   ğŸ”¢ Tentatives: ${attempt}`);
      console.log("â•".repeat(70) + "\n");

      return {
        imagePath: result.imagePath,
        description: result.description,
        attempts: attempt,
        analysisDetails: analysis,
      };
    } catch (error) {
      lastError = error as Error;
      console.error(`   âŒ Ã‰chec: ${lastError.message.substring(0, 200)}`);

      if (attempt < CONFIG.maxRetries) {
        const delay = Math.min(
          CONFIG.initialDelayMs *
            Math.pow(CONFIG.backoffMultiplier, attempt - 1),
          CONFIG.maxDelayMs
        );
        console.log(`   â³ Nouveau essai dans ${delay}ms...`);
        await sleep(delay);
      }
    }
  }

  throw new Error(
    `Ã‰chec aprÃ¨s ${CONFIG.maxRetries} tentatives. ${lastError?.message}`
  );
}

// ============================================================================
// FONCTION AVEC PROGRESS CALLBACK POUR STREAMING SSE
// ============================================================================

export type ProgressCallback = (event: {
  type: 'log' | 'step' | 'error';
  icon?: string;
  message?: string;
  step?: string;
  status?: 'pending' | 'loading' | 'done' | 'error';
}) => void;

export async function generateBeforeAfterWithProgress(
  originalImagePath: string,
  instructions: GenerationInstruction[],
  outputDir: string,
  generationId: string,
  onProgress: ProgressCallback,
  options: GenerationOptions = {}
): Promise<GenerationResult> {
  const startTime = Date.now();

  const log = (icon: string, message: string) => {
    console.log(`${icon} ${message}`);
    onProgress({ type: 'log', icon, message });
  };

  const setStep = (step: string, status: 'pending' | 'loading' | 'done' | 'error') => {
    onProgress({ type: 'step', step, status });
  };

  log("ğŸ¤–", "SYSTÃˆME AGENTIQUE DE GÃ‰NÃ‰RATION AVANT/APRÃˆS");
  log("ğŸ“‹", `${instructions.length} instruction(s) de l'utilisateur`);
  log("ğŸ†”", `ID: ${generationId}`);

  for (let i = 0; i < instructions.length; i++) {
    const instr = instructions[i];
    log("ğŸ“Œ", `Instruction ${i + 1}: "${instr.location}" - ${instr.referenceName || "(sans nom)"}`);
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // CHARGEMENT DES IMAGES
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  setStep('upload', 'loading');
  log("ğŸ“¸", "Chargement des images depuis S3...");
  
  const originalImage = await prepareImageForAPI(originalImagePath);
  log("âœ“", `Original: ${(originalImage.base64.length / 1024).toFixed(0)} KB`);

  const referenceImages: { base64: string; mimeType: string }[] = [];
  for (let i = 0; i < instructions.length; i++) {
    const refImage = await prepareImageForAPI(instructions[i].referenceImagePath);
    referenceImages.push(refImage);
    log("âœ“", `RÃ©fÃ©rence ${i + 1}: ${(refImage.base64.length / 1024).toFixed(0)} KB`);
  }
  
  setStep('upload', 'done');

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PHASE 1: ANALYSE AGENTIQUE
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  setStep('analyze', 'loading');
  log("ğŸ”¬", "PHASE 1: Analyse intelligente de l'image");
  log("ğŸ§ ", "Identification des Ã©lÃ©ments de la piÃ¨ce...");

  const analysis = await analyzeImageWithAgent(originalImage);
  
  log("âœ“", `Analyse terminÃ©e: ${(analysis.description || 'Analyse complÃ¨te').substring(0, 100)}...`);
  setStep('analyze', 'done');

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PHASE 2: PLANIFICATION DES MODIFICATIONS
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  setStep('plan', 'loading');
  log("ğŸ“Š", "PHASE 2: Planification et mapping des zones");
  log("ğŸ—ºï¸", "CrÃ©ation du plan de modification...");

  const plan = await planModificationsWithAgent(
    analysis,
    instructions,
    referenceImages
  );

  log("âœ“", `Plan crÃ©Ã©: ${plan.tasks?.length || 0} tÃ¢che(s) de modification`);
  if (plan.tasks && plan.tasks.length > 0) {
    for (const task of plan.tasks) {
      log("ğŸ“", `Zone: ${task.zoneName || 'Zone'} - ${(task.actionDescription || 'Modification').substring(0, 60)}`);
    }
  }
  setStep('plan', 'done');

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // PHASE 3: GÃ‰NÃ‰RATION AVEC RETRY
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  setStep('generate', 'loading');
  log("ğŸ¨", "PHASE 3: GÃ©nÃ©ration de l'image avec Gemini");

  let lastError: Error | null = null;

  for (let attempt = 1; attempt <= CONFIG.maxRetries; attempt++) {
    log("ğŸ”„", `Tentative ${attempt}/${CONFIG.maxRetries}`);

    try {
      const prompt =
        attempt === 1
          ? plan.globalPrompt
          : buildSimplifiedRetryPrompt(instructions, plan.tasks, attempt);

      log("ğŸ“", `Envoi du prompt (${prompt.length} caractÃ¨res)...`);

      const result = await generateWithNanoBanana(
        originalImage,
        referenceImages,
        prompt,
        outputDir,
        generationId
      );

      const duration = ((Date.now() - startTime) / 1000).toFixed(1);

      setStep('generate', 'done');
      log("âœ…", `GÃ‰NÃ‰RATION RÃ‰USSIE en ${duration}s!`);
      log("ğŸ“", `Image sauvegardÃ©e: ${result.imagePath}`);

      return {
        imagePath: result.imagePath,
        description: result.description,
        attempts: attempt,
        analysisDetails: analysis,
      };
    } catch (error) {
      lastError = error as Error;
      log("âŒ", `Ã‰chec: ${(lastError?.message || 'Erreur inconnue').substring(0, 150)}`);

      if (attempt < CONFIG.maxRetries) {
        const delay = Math.min(
          CONFIG.initialDelayMs * Math.pow(CONFIG.backoffMultiplier, attempt - 1),
          CONFIG.maxDelayMs
        );
        log("â³", `Nouveau essai dans ${delay}ms...`);
        await sleep(delay);
      }
    }
  }

  setStep('generate', 'error');
  onProgress({ 
    type: 'error', 
    message: `Ã‰chec aprÃ¨s ${CONFIG.maxRetries} tentatives: ${lastError?.message}` 
  });
  
  throw new Error(
    `Ã‰chec aprÃ¨s ${CONFIG.maxRetries} tentatives. ${lastError?.message}`
  );
}

// Prompt simplifiÃ© pour les retries
function buildSimplifiedRetryPrompt(
  instructions: GenerationInstruction[],
  tasks: ModificationTask[],
  attempt: number
): string {
  const mods = instructions
    .map((instr, i) => {
      const relevantTasks = tasks.filter((t) => t.referenceIndex === i);
      const zones = relevantTasks.map((t) => t.zone.name).join(", ");
      return `${i + 1}. Zones: ${zones || instr.location}
   Appliquer le matÃ©riau de l'IMAGE ${i + 2}${
        instr.referenceName ? ` (${instr.referenceName})` : ""
      }`;
    })
    .join("\n\n");

  return `GÃ©nÃ¨re une image APRÃˆS RÃ‰NOVATION basÃ©e sur l'IMAGE 1.

MODIFICATIONS REQUISES:
${mods}

RÃˆGLES:
- Appliquer chaque matÃ©riau sur 100% des zones indiquÃ©es
- Garder exactement la mÃªme perspective
- Rendu photorÃ©aliste professionnel

GÃ©nÃ¨re l'image maintenant.`;
}

// ============================================================================
// FONCTIONS UTILITAIRES EXPORTÃ‰ES
// ============================================================================

/**
 * Analyse une image pour identifier les zones modifiables (utilisable depuis l'UI)
 */
export async function analyzeImage(imagePath: string): Promise<string> {
  const imageData = await prepareImageForAPI(imagePath);

  const response = await ai.models.generateContent({
    model: MODELS.ANALYZER,
    contents: [
      {
        text: `Analyse cette image d'un espace et identifie TOUS les Ã©lÃ©ments modifiables.

Pour chaque Ã©lÃ©ment:
1. **Nom**: Description prÃ©cise (ex: "Mur gauche", "Sol parquet")
2. **Ã‰tat actuel**: Type de revÃªtement actuel
3. **Modifications possibles**: Alternatives (parquet, carrelage, peinture...)

Sois exhaustif.`,
      },
      { inlineData: { mimeType: imageData.mimeType, data: imageData.base64 } },
    ],
  });

  return (
    response.candidates?.[0]?.content?.parts?.[0]?.text ||
    "Analyse non disponible"
  );
}

/**
 * Valide une image de rÃ©fÃ©rence (matÃ©riau)
 */
export async function validateReference(imagePath: string): Promise<{
  valid: boolean;
  material?: string;
  quality?: string;
  suggestions?: string;
}> {
  const imageData = await prepareImageForAPI(imagePath);

  const response = await ai.models.generateContent({
    model: MODELS.ANALYZER,
    contents: [
      {
        text: `Cette image doit servir de rÃ©fÃ©rence pour un matÃ©riau.

RÃ©ponds avec ce JSON (sans markdown):
{
  "valid": true ou false,
  "material": "nom du matÃ©riau identifiÃ©",
  "quality": "excellente", "bonne", "moyenne" ou "insuffisante",
  "suggestions": "conseils si qualitÃ© non excellente"
}`,
      },
      { inlineData: { mimeType: imageData.mimeType, data: imageData.base64 } },
    ],
  });

  try {
    const text = response.candidates?.[0]?.content?.parts?.[0]?.text || "";
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (jsonMatch) return JSON.parse(jsonMatch[0]);
  } catch (e) {
    console.warn("Parsing validation Ã©chouÃ©:", e);
  }

  return { valid: true, material: "MatÃ©riau", quality: "inconnue" };
}
